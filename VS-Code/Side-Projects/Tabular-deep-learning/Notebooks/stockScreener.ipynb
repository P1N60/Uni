{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Screener: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Installation (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries the first time\n",
    "# !pip install -q ipynb yfinance pandas pathlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.metrics import rmse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model settings\n",
    "modelName = 'stockScreenerV6.0'\n",
    "trainingData = 'stockData.csv'\n",
    "getNewData = True \n",
    "trainNewModel = True\n",
    "predictionTarget = 'NVO'  # 'ALL' for all tickers, 'None' for no prediction\n",
    "\n",
    "# Training parameters\n",
    "trainingSize = 150  # Number of stocks to use for training\n",
    "timeFrame = 'max'   # Options: '1d', '5d', '1mo', '3mo', '6mo', '1y', '2y', '5y', '10y', 'ytd', 'max'\n",
    "yNames = ['Future Year Change']\n",
    "catNames = ['Date']\n",
    "contNames = ['Open', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'EV/EBIT', 'ROIC']\n",
    "epochs = 3\n",
    "\n",
    "# Testing parameters\n",
    "testSize = 420  # Number of stocks to test, 'ALL' for all non-training stocks\n",
    "\n",
    "# Paths\n",
    "basePath = Path.cwd().parent\n",
    "dataFolder = basePath / 'TrainingData'\n",
    "modelFolder = basePath.parent / 'TrainedModels' / 'stockScreener'\n",
    "testFolder = basePath / 'TestData'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicate Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(testFolder / 'tickers.csv')\n",
    "df.drop_duplicates().to_csv(testFolder / 'tickers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndustry(tickerSymbol):\n",
    "    \"\"\"Fetches the industry of the given ticker symbol.\"\"\"\n",
    "    try:\n",
    "        return yf.Ticker(tickerSymbol).info.get('industry', 'Unknown')\n",
    "    except Exception as e:\n",
    "        return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFutureYearChange(ticker_symbol, timeframe, buffer=1):\n",
    "    valid_periods = ['1d', '5d', '1mo', '3mo', '6mo', '1y', '2y', '5y', '10y', 'ytd', 'max']\n",
    "    try:\n",
    "        if timeframe == 'max':\n",
    "            future_change = yf.Ticker(ticker_symbol).history(period='max')\n",
    "            future_change['Future Year Change'] = (future_change['Close'].shift(-252) / future_change['Close'] - 1)\n",
    "            future_change = future_change.dropna(subset=['Future Year Change'])\n",
    "        else:\n",
    "            # Calculate the extended timeframe\n",
    "            extended_timeframe = valid_periods[min(valid_periods.index(timeframe) + buffer, len(valid_periods) - 1)]\n",
    "            future_change = yf.Ticker(ticker_symbol).history(period=extended_timeframe)\n",
    "            future_change['Future Year Change'] = (future_change['Close'].shift(-252) / future_change['Close'] - 1)\n",
    "\n",
    "            # Calculate the end date and start date based on the timeframe\n",
    "            end_date = future_change.index[-1] - pd.DateOffset(years=1)\n",
    "            start_date = end_date - pd.DateOffset(years=int(timeframe[:-1]))\n",
    "            future_change = future_change.loc[start_date:end_date].dropna(subset=['Future Year Change'])\n",
    "        return future_change\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEVComponents(tickerSymbol):\n",
    "    \"\"\"Fetches static EV components (total debt, cash, shares outstanding).\"\"\"\n",
    "    try:\n",
    "        info = yf.Ticker(tickerSymbol).info\n",
    "        return info.get('totalDebt', 0), info.get('totalCash', 0), info.get('sharesOutstanding', None)\n",
    "    except Exception as e:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateApproxEBIT(tickerSymbol):\n",
    "    \"\"\"Estimates EBIT based on revenue and operating income.\"\"\"\n",
    "    try:\n",
    "        info = yf.Ticker(tickerSymbol).info\n",
    "        revenue = info.get('totalRevenue', None)\n",
    "        operatingIncome = info.get('operatingIncome', None)\n",
    "        return operatingIncome if operatingIncome else (revenue * 0.15 if revenue else None)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichDataWithMetrics(histData):\n",
    "    \"\"\"Adds EV/EBIT and ROIC to the historical data.\"\"\"\n",
    "    for ticker in histData['Ticker'].unique():\n",
    "        try:\n",
    "            totalDebt, cash, sharesOutstanding = getEVComponents(ticker)\n",
    "            ebit = calculateApproxEBIT(ticker)\n",
    "\n",
    "            if sharesOutstanding and ebit and ebit != 0:\n",
    "                histData.loc[histData['Ticker'] == ticker, 'EV/EBIT'] = (\n",
    "                    (histData['Close'] * sharesOutstanding + totalDebt - cash) / ebit\n",
    "                )\n",
    "\n",
    "                taxRate = 0.21\n",
    "                nopat = ebit * (1 - taxRate)\n",
    "                investedCapital = totalDebt + (histData['Close'] * sharesOutstanding) - cash\n",
    "                histData.loc[histData['Ticker'] == ticker, 'ROIC'] = nopat / investedCapital\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return histData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTickerDataFrom1YrAgo(ticker_symbol):\n",
    "    try:\n",
    "        # Fetch ticker data\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "\n",
    "        # Define the date range: one year ago to today\n",
    "        today = datetime.today()\n",
    "        one_year_ago = today - timedelta(days=365)\n",
    "\n",
    "        # Fetch historical data for one year ago\n",
    "        hist = ticker.history(start=(one_year_ago - timedelta(days=30)).strftime('%Y-%m-%d'), \n",
    "                              end=(one_year_ago + timedelta(days=0)).strftime('%Y-%m-%d'))\n",
    "        if hist.empty:\n",
    "            raise ValueError(f\"No historical data available for {ticker_symbol} around {one_year_ago.strftime('%Y-%m-%d')}.\")\n",
    "\n",
    "        # Extract the closest data point to one year ago\n",
    "        row = hist.iloc[0]  # Get the first available entry within the date range\n",
    "\n",
    "        # Price today\n",
    "        price_today = ticker.history(period='1d')['Close'].iloc[-1]\n",
    "\n",
    "        # Calculate future price change (from one year ago to today)\n",
    "        price_change_future = ((price_today - row['Close']) / row['Close']) if row['Close'] else None\n",
    "\n",
    "        # Collect additional data\n",
    "        total_debt, cash, shares_outstanding = getEVComponents(ticker_symbol)\n",
    "        ebit = calculateApproxEBIT(ticker_symbol)\n",
    "        ev = (row['Close'] * shares_outstanding) + total_debt - cash if shares_outstanding else None\n",
    "        ev_ebit = ev / ebit if ebit else None\n",
    "        market_cap = row['Close'] * shares_outstanding if shares_outstanding else None\n",
    "        tax_rate = 0.21\n",
    "        nopat = ebit * (1 - tax_rate) if ebit else None\n",
    "        invested_capital = total_debt + market_cap - cash if market_cap and total_debt and cash else None\n",
    "        roic = nopat / invested_capital if nopat and invested_capital else None\n",
    "        industry = getIndustry(ticker_symbol)\n",
    "\n",
    "        # Return as a DataFrame\n",
    "        return pd.DataFrame([{\n",
    "            'Date': row.name,\n",
    "            'Open': row['Open'],\n",
    "            'High': row['High'],\n",
    "            'Low': row['Low'],\n",
    "            'Close': row['Close'],\n",
    "            'Volume': row['Volume'],\n",
    "            'Dividends': row.get('Dividends', 0.0),\n",
    "            'Stock Splits': row.get('Stock Splits', 0.0),\n",
    "            'Future Year Change': price_change_future,\n",
    "            'Industry': industry,\n",
    "            'EV/EBIT': ev_ebit,\n",
    "            'ROIC': roic\n",
    "        }])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker_symbol}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTickerData(ticker_symbol):\n",
    "    try:\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "        hist = ticker.history(period='1d')\n",
    "        total_debt, cash, shares_outstanding = getEVComponents(ticker_symbol)\n",
    "        ebit = calculateApproxEBIT(ticker_symbol)\n",
    "        ev = (hist['Close'].iloc[-1] * shares_outstanding) + total_debt - cash\n",
    "        ev_ebit = ev / ebit if ebit else None\n",
    "        market_cap = hist['Close'].iloc[-1] * shares_outstanding\n",
    "        tax_rate = 0.21\n",
    "        nopat = ebit * (1 - tax_rate) if ebit else None\n",
    "        invested_capital = total_debt + market_cap - cash\n",
    "        roic = nopat / invested_capital if nopat and invested_capital else None\n",
    "        industry = getIndustry(ticker_symbol)\n",
    "        \n",
    "        # Add the 'Date' column\n",
    "        date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "        return pd.DataFrame([{\n",
    "            'Date': date,\n",
    "            'Open': hist['Open'].iloc[-1],\n",
    "            'High': hist['High'].iloc[-1],\n",
    "            'Low': hist['Low'].iloc[-1],\n",
    "            'Close': hist['Close'].iloc[-1],\n",
    "            'Volume': hist['Volume'].iloc[-1],\n",
    "            'Dividends': hist.get('Dividends', pd.Series([0.0])).iloc[-1],\n",
    "            'Stock Splits': hist.get('Stock Splits', pd.Series([0.0])).iloc[-1],\n",
    "            'EV/EBIT': ev_ebit,\n",
    "            'Market Cap': market_cap,\n",
    "            'ROIC': roic,\n",
    "            'Industry': industry\n",
    "        }])\n",
    "    except Exception as e:\n",
    "\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Process Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PVG: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$GUT-A: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/GUT-A?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=GUT-A&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$LYG-A: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/LYG-A?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=LYG-A&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$SPEX: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$PLCC: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$MLVF: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/MLVF?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=MLVF&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$HNR: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$HIG.W: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/HIG.W?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=HIG.W&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$OIBR: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$BSMX: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$MER-F: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/MER-F?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=MER-F&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$CYT: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/CYT?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=CYT&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$PMFG: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$NUAN: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$MSBF: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$TEU: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$SZC: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$EXA: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$RCII: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$KKD: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$CBL-E: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/CBL-E?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=CBL-E&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$INT: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$TICC: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$BIE: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$RRD: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$STL: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$BML-H: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/BML-H?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=BML-H&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$MTSL: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$JMT: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$FISH: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$HSA: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$PULB: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$BPZ: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$OXF: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$LOCK: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$MBLX: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$SEV: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/SEV?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=SEV&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$GRT-H: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/GRT-H?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=GRT-H&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$CECE: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$ANH-A: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/ANH-A?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=ANH-A&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$PBI-B: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/PBI-B?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=PBI-B&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$HOME: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$NES: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$COB: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$IMRS: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$HOVU: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$RZA: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$CREE: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$IRE-B: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/IRE-B?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=IRE-B&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$WAGE: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$PMBC: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$IKAN: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$IRG: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$GAT: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$MFSF: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$INWK: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$CLAC: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$TUES: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$DRU: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$ELRC: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$BML-G: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/BML-G?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=BML-G&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$SXCP: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$PMCS: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$CHK: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/CHK?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=CHK&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$ELS-C: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/ELS-C?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=ELS-C&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$BLMT: possibly delisted; no timezone found\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$STI.A: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/STI.A?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=STI.A&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$SNHN: possibly delisted; no timezone found\n",
      "404 Client Error: Not Found for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/SNHN?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=SNHN&crumb=TLJxoxQPcjU\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$SPU: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$ALCS: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$PNY: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n",
      "$STSI: possibly delisted; no price data found  (1d 1926-02-16 -> 2025-01-22)\n",
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\223849276.py:12: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  histData = pd.concat([histData, data])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved: 506704 rows\n"
     ]
    }
   ],
   "source": [
    "tickers = pd.read_csv(testFolder / 'tickers.csv')['Ticker']\n",
    "trainingTickers = np.random.choice(tickers, size=trainingSize, replace=False)\n",
    "\n",
    "if getNewData:\n",
    "    histData = pd.DataFrame()\n",
    "\n",
    "    for ticker in trainingTickers:\n",
    "        try:\n",
    "            data = calculateFutureYearChange(ticker, timeFrame)\n",
    "            data['Ticker'] = ticker\n",
    "            data['Industry'] = getIndustry(ticker)\n",
    "            histData = pd.concat([histData, data])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    histData.reset_index(inplace=True)\n",
    "    histData = enrichDataWithMetrics(histData)\n",
    "    histData.to_csv(dataFolder / trainingData, index=False)\n",
    "    print(f\"Training data saved: {len(histData)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with no EV/EBIT- or ROIC data\n",
    "df = pd.read_csv(dataFolder / trainingData)\n",
    "dfCleaned = df.dropna(subset=['EV/EBIT', 'ROIC'])\n",
    "dfCleaned.to_csv(dataFolder / trainingData, index=False)\n",
    "\n",
    "splits = RandomSplitter(valid_pct=0.2)(range_of(dfCleaned))\n",
    "\n",
    "to = TabularPandas(\n",
    "    df, procs=[Categorify, FillMissing, Normalize],\n",
    "    y_names=yNames, cat_names=catNames, cont_names=contNames, splits=splits)\n",
    "\n",
    "dls = to.dataloaders(bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='98' class='' max='5724' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.71% [98/5724 00:04&lt;04:15 201.2215]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "if trainNewModel:\n",
    "    learn = tabular_learner(dls, metrics=[rmse, mae])\n",
    "    learn.fit_one_cycle(epochs)\n",
    "    learn.export(modelFolder / f'{modelName}.pkl')\n",
    "    print(\"Model training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logEvaluation(model_name, mae, rmse, r2, model_folder, test_tickers):\n",
    "    \"\"\"Log evaluation metrics to CSV file\"\"\"\n",
    "    log_file = model_folder / \"modelEvaluations.csv\"\n",
    "    \n",
    "    new_entry_df = pd.DataFrame([{\n",
    "        \"Model Name\": modelName,\n",
    "        \"Timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "        \"MAE\": f'{mae:.3f}',\n",
    "        \"RMSE\": f'{rmse:.3f}',\n",
    "        \"R2\": f'{r2:.3f}',\n",
    "        \"Epochs\": epochs,\n",
    "        \"Training Size\": trainingSize,\n",
    "        \"Test Size\": len(test_tickers),\n",
    "        \"Cat Names\": catNames,\n",
    "        \"Cont Names\": contNames,\n",
    "    }])\n",
    "    \n",
    "    try:\n",
    "        log_df = pd.read_csv(log_file)\n",
    "        log_df = pd.concat([log_df, new_entry_df], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        log_df = new_entry_df\n",
    "        \n",
    "    log_df.to_csv(log_file, index=False)\n",
    "    print(f\"Logged evaluation results to {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(filtered_df, model_name, model_folder):\n",
    "    \"\"\"Create and save visualization plots\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    actuals = filtered_df['Actual']\n",
    "    predictions = filtered_df['Predicted']\n",
    "    plt.scatter(actuals, predictions, alpha=0.7, label='Predictions')\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(actuals.min(), predictions.min())\n",
    "    max_val = max(actuals.max(), predictions.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], \n",
    "             color='red', linestyle='--', label='Perfect Prediction')\n",
    "    \n",
    "    plt.title(f'Predicted vs. Actual Returns - {model_name}', fontsize=14)\n",
    "    plt.xlabel('Actual Returns', fontsize=12)\n",
    "    plt.ylabel('Predicted Returns', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.5)\n",
    "    \n",
    "    # Residual plot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.scatter(predictions, filtered_df['Residual'], alpha=0.7)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.title('Residual Plot', fontsize=14)\n",
    "    plt.xlabel('Predicted Returns', fontsize=12)\n",
    "    plt.ylabel('Residual', fontsize=12)\n",
    "    plt.grid(alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(learn, test_tickers, model_name, model_folder, cont_names, cat_names):\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "    test_data_list = []\n",
    "\n",
    "    for ticker in test_tickers:\n",
    "        try:\n",
    "            test_data = getTickerDataFrom1YrAgo(ticker)\n",
    "            if test_data.empty:\n",
    "                print(f\"Skipping {ticker} due to insufficient valid data\")\n",
    "                continue\n",
    "            test_data_list.append(test_data)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not test_data_list:\n",
    "        print(\"No valid test data collected\")\n",
    "        return None, None, None\n",
    "\n",
    "    combined_test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "    test_dl = learn.dls.test_dl(combined_test_data)\n",
    "    preds, targs = learn.get_preds(dl=test_dl)\n",
    "    predictions = preds.numpy()\n",
    "    actuals = targs.numpy()\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Predicted': predictions.flatten(),\n",
    "        'Actual': actuals.flatten()\n",
    "    })\n",
    "\n",
    "    results_df['Residual'] = results_df['Actual'] - results_df['Predicted']\n",
    "    outlier_threshold = 2 * results_df['Residual'].std()\n",
    "    filtered_df = results_df[abs(results_df['Residual']) <= outlier_threshold]\n",
    "\n",
    "    mae = np.mean(np.abs(filtered_df['Residual']))\n",
    "    rmse = np.sqrt(np.mean(filtered_df['Residual']**2))\n",
    "    r2 = 1 - (np.sum(filtered_df['Residual']**2) / np.sum((filtered_df['Actual'] - filtered_df['Actual'].mean())**2))\n",
    "\n",
    "    logEvaluation(model_name, mae, rmse, r2, model_folder, test_tickers)\n",
    "    plotResults(filtered_df, model_name, model_folder)\n",
    "\n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Future Year Change</th>\n",
       "      <th>Industry</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>ROIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-26 00:00:00-05:00</td>\n",
       "      <td>101.445632</td>\n",
       "      <td>102.009439</td>\n",
       "      <td>101.297268</td>\n",
       "      <td>101.564331</td>\n",
       "      <td>1851400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.202181</td>\n",
       "      <td>Drug Manufacturers - General</td>\n",
       "      <td>7.979916</td>\n",
       "      <td>0.098999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date        Open        High         Low       Close  \\\n",
       "0 2023-12-26 00:00:00-05:00  101.445632  102.009439  101.297268  101.564331   \n",
       "\n",
       "      Volume  Dividends  Stock Splits  Future Year Change  \\\n",
       "0  1851400.0        0.0           0.0           -0.202181   \n",
       "\n",
       "                       Industry   EV/EBIT      ROIC  \n",
       "0  Drug Manufacturers - General  7.979916  0.098999  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = getTickerDataFrom1YrAgo(\"NVO\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BSI: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BSI: No historical data available for BSI around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CMS-B: possibly delisted; no timezone found\n",
      "$GEQ: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CMS-B: No historical data available for CMS-B around 2024-01-23.\n",
      "Error fetching data for GEQ: No historical data available for GEQ around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MTU: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MTU: No historical data available for MTU around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DDE: possibly delisted; no timezone found\n",
      "$CEDU: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DDE: No historical data available for DDE around 2024-01-23.\n",
      "Error fetching data for CEDU: No historical data available for CEDU around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AEZS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AEZS: No historical data available for AEZS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ZB-F: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ZB-F: No historical data available for ZB-F around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USB-M: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for USB-M: No historical data available for USB-M around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MGU: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MGU: No historical data available for MGU around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NXTM: possibly delisted; no timezone found\n",
      "$HAST: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NXTM: No historical data available for NXTM around 2024-01-23.\n",
      "Error fetching data for HAST: No historical data available for HAST around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$STML: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for STML: No historical data available for STML around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LUK: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$NEWS: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for LUK: No historical data available for LUK around 2024-01-23.\n",
      "Error fetching data for NEWS: No historical data available for NEWS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HJN: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$HOVU: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HJN: No historical data available for HJN around 2024-01-23.\n",
      "Error fetching data for HOVU: No historical data available for HOVU around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JONE: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for JONE: No historical data available for JONE around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DRCO: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DRCO: No historical data available for DRCO around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BLC: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BLC: No historical data available for BLC around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CHS-A: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CHS-A: No historical data available for CHS-A around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NPV-C: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NPV-C: No historical data available for NPV-C around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RAS-B: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for RAS-B: No historical data available for RAS-B around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MPR: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MPR: No historical data available for MPR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MSON: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MSON: No historical data available for MSON around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PFG-B: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PFG-B: No historical data available for PFG-B around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$IO: possibly delisted; no timezone found\n",
      "$CGG: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for IO: No historical data available for IO around 2024-01-23.\n",
      "Error fetching data for CGG: No historical data available for CGG around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PMC: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PMC: No historical data available for PMC around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GSJK: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GSJK: No historical data available for GSJK around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ATV: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ATV: No historical data available for ATV around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$IFEU: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for IFEU: No historical data available for IFEU around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BF.B: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BF.B: No historical data available for BF.B around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$INVN: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23) (Yahoo error = \"Data doesn't exist for startDate = 1703394000, endDate = 1705986000\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for INVN: No historical data available for INVN around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HEP: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HEP: No historical data available for HEP around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NRF-A: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NRF-A: No historical data available for NRF-A around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PYC: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$BAGL: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PYC: No historical data available for PYC around 2024-01-23.\n",
      "Error fetching data for BAGL: No historical data available for BAGL around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MTS: Period '1d' is invalid, must be one of ['1mo', '3mo', '6mo', 'ytd', '1y', '2y', '5y', '10y', 'max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MTS: single positional indexer is out-of-bounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CTRL: possibly delisted; no timezone found\n",
      "$LMOS: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CTRL: No historical data available for CTRL around 2024-01-23.\n",
      "Error fetching data for LMOS: No historical data available for LMOS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JOBS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for JOBS: No historical data available for JOBS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TVL: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$JMBA: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TVL: No historical data available for TVL around 2024-01-23.\n",
      "Error fetching data for JMBA: No historical data available for JMBA around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SFE: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SFE: No historical data available for SFE around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ZGNX: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ZGNX: No historical data available for ZGNX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GSVC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GSVC: No historical data available for GSVC around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NTC-C: possibly delisted; no timezone found\n",
      "$BKMU: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NTC-C: No historical data available for NTC-C around 2024-01-23.\n",
      "Error fetching data for BKMU: No historical data available for BKMU around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AXLL: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AXLL: No historical data available for AXLL around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GLCH: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$LIME: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$BBOX: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GLCH: No historical data available for GLCH around 2024-01-23.\n",
      "Error fetching data for LIME: No historical data available for LIME around 2024-01-23.\n",
      "Error fetching data for BBOX: No historical data available for BBOX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$KMR: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for KMR: No historical data available for KMR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TAXI: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TAXI: No historical data available for TAXI around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PRY: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PRY: No historical data available for PRY around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PHA: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$ANCI: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PHA: No historical data available for PHA around 2024-01-23.\n",
      "Error fetching data for ANCI: No historical data available for ANCI around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MRTX: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MRTX: No historical data available for MRTX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GTXI: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GTXI: No historical data available for GTXI around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DO: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DO: No historical data available for DO around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CHK-D: possibly delisted; no timezone found\n",
      "$GCH: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CHK-D: No historical data available for CHK-D around 2024-01-23.\n",
      "Error fetching data for GCH: No historical data available for GCH around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DISCK: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DISCK: No historical data available for DISCK around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GNCMA: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GNCMA: No historical data available for GNCMA around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$IMPV: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for IMPV: No historical data available for IMPV around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BODY: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BODY: No historical data available for BODY around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FCH-A: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for FCH-A: No historical data available for FCH-A around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JMT: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for JMT: No historical data available for JMT around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SSS: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SSS: No historical data available for SSS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DTSI: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DTSI: No historical data available for DTSI around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FHN-A: possibly delisted; no timezone found\n",
      "$PSE: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for FHN-A: No historical data available for FHN-A around 2024-01-23.\n",
      "Error fetching data for PSE: No historical data available for PSE around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PICO: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PICO: No historical data available for PICO around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$OTEL: possibly delisted; no timezone found\n",
      "$ONTY: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for OTEL: No historical data available for OTEL around 2024-01-23.\n",
      "Error fetching data for ONTY: No historical data available for ONTY around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$KORS: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$ABCO: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$CCIH: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for KORS: No historical data available for KORS around 2024-01-23.\n",
      "Error fetching data for ABCO: No historical data available for ABCO around 2024-01-23.\n",
      "Error fetching data for CCIH: No historical data available for CCIH around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HYV: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HYV: No historical data available for HYV around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GALTW: possibly delisted; no timezone found\n",
      "$PCBK: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GALTW: No historical data available for GALTW around 2024-01-23.\n",
      "Error fetching data for PCBK: No historical data available for PCBK around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CLNY: possibly delisted; no timezone found\n",
      "$XOOM: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CLNY: No historical data available for CLNY around 2024-01-23.\n",
      "Error fetching data for XOOM: No historical data available for XOOM around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$REN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for REN: No historical data available for REN around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TRIT: possibly delisted; no timezone found\n",
      "$AYN: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TRIT: No historical data available for TRIT around 2024-01-23.\n",
      "Error fetching data for AYN: No historical data available for AYN around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ETH: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23) (Yahoo error = \"Data doesn't exist for startDate = 1703394000, endDate = 1705986000\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ETH: No historical data available for ETH around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AETI: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AETI: No historical data available for AETI around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$KNL: possibly delisted; no timezone found\n",
      "$ANLY: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for KNL: No historical data available for KNL around 2024-01-23.\n",
      "Error fetching data for ANLY: No historical data available for ANLY around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ABV: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ABV: No historical data available for ABV around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XXIA: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for XXIA: No historical data available for XXIA around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$REG-F: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for REG-F: No historical data available for REG-F around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SYNL: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SYNL: No historical data available for SYNL around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$STI.B: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for STI.B: No historical data available for STI.B around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TTHI: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$NSTG: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TTHI: No historical data available for TTHI around 2024-01-23.\n",
      "Error fetching data for NSTG: single positional indexer is out-of-bounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AIMC: possibly delisted; no timezone found\n",
      "$SHOR: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AIMC: No historical data available for AIMC around 2024-01-23.\n",
      "Error fetching data for SHOR: No historical data available for SHOR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LSE-C: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for LSE-C: No historical data available for LSE-C around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$REXX: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$LAS: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$HXM: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for REXX: No historical data available for REXX around 2024-01-23.\n",
      "Error fetching data for LAS: No historical data available for LAS around 2024-01-23.\n",
      "Error fetching data for HXM: No historical data available for HXM around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ARO: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ARO: No historical data available for ARO around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CHL: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CHL: No historical data available for CHL around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TWX: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TWX: No historical data available for TWX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MWRX: possibly delisted; no timezone found\n",
      "$WAVX: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MWRX: No historical data available for MWRX around 2024-01-23.\n",
      "Error fetching data for WAVX: No historical data available for WAVX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HEOP: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HEOP: No historical data available for HEOP around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AIY: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AIY: No historical data available for AIY around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CHUY: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CHUY: No historical data available for CHUY around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MXT: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MXT: No historical data available for MXT around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$EXL: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for EXL: No historical data available for EXL around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BOFI: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$CYBX: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BOFI: No historical data available for BOFI around 2024-01-23.\n",
      "Error fetching data for CYBX: No historical data available for CYBX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MET-A: possibly delisted; no timezone found\n",
      "$MCOX: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MET-A: No historical data available for MET-A around 2024-01-23.\n",
      "Error fetching data for MCOX: No historical data available for MCOX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$COBR: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for COBR: No historical data available for COBR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PJC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PJC: No historical data available for PJC around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PHII: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PHII: No historical data available for PHII around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ETFC: possibly delisted; no timezone found\n",
      "$IPXL: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ETFC: No historical data available for ETFC around 2024-01-23.\n",
      "Error fetching data for IPXL: No historical data available for IPXL around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$REDF: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for REDF: No historical data available for REDF around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NEPT: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$PNRA: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NEPT: No historical data available for NEPT around 2024-01-23.\n",
      "Error fetching data for PNRA: No historical data available for PNRA around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ROIAK: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$CLBH: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ROIAK: No historical data available for ROIAK around 2024-01-23.\n",
      "Error fetching data for CLBH: No historical data available for CLBH around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XCO: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for XCO: No historical data available for XCO around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SPWR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SPWR: No historical data available for SPWR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PPX: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PPX: No historical data available for PPX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PRMW: possibly delisted; no timezone found\n",
      "$AMBT: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PRMW: No historical data available for PRMW around 2024-01-23.\n",
      "Error fetching data for AMBT: No historical data available for AMBT around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$IMMU: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for IMMU: No historical data available for IMMU around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AMOT: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AMOT: No historical data available for AMOT around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$EXL-B: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for EXL-B: No historical data available for EXL-B around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RBS: possibly delisted; no timezone found\n",
      "$DWRE: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for RBS: No historical data available for RBS around 2024-01-23.\n",
      "Error fetching data for DWRE: No historical data available for DWRE around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ISG: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ISG: No historical data available for ISG around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CS: No historical data available for CS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GIMO: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GIMO: No historical data available for GIMO around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VAR: possibly delisted; no timezone found\n",
      "$CTX: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for VAR: No historical data available for VAR around 2024-01-23.\n",
      "Error fetching data for CTX: No historical data available for CTX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BRSS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BRSS: No historical data available for BRSS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ARCI: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ARCI: No historical data available for ARCI around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PSUN: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PSUN: No historical data available for PSUN around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SWJ: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SWJ: No historical data available for SWJ around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HFBC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HFBC: No historical data available for HFBC around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VVTV: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$CSFS: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for VVTV: No historical data available for VVTV around 2024-01-23.\n",
      "Error fetching data for CSFS: No historical data available for CSFS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NNN-D: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NNN-D: No historical data available for NNN-D around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PEB-A: possibly delisted; no timezone found\n",
      "$HGR: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PEB-A: No historical data available for PEB-A around 2024-01-23.\n",
      "Error fetching data for HGR: No historical data available for HGR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ADRD: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ADRD: No historical data available for ADRD around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RESI: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for RESI: No historical data available for RESI around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NNC-C: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NNC-C: No historical data available for NNC-C around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CHS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CHS: No historical data available for CHS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SFG: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SFG: No historical data available for SFG around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SCHN: possibly delisted; no timezone found\n",
      "$RRST: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SCHN: No historical data available for SCHN around 2024-01-23.\n",
      "Error fetching data for RRST: No historical data available for RRST around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BRS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BRS: No historical data available for BRS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MINI: possibly delisted; no timezone found\n",
      "$VLTR: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MINI: No historical data available for MINI around 2024-01-23.\n",
      "Error fetching data for VLTR: No historical data available for VLTR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$OCR: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for OCR: No historical data available for OCR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$KCAP: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for KCAP: No historical data available for KCAP around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VCI: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for VCI: No historical data available for VCI around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MHY: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$DXM: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MHY: No historical data available for MHY around 2024-01-23.\n",
      "Error fetching data for DXM: No historical data available for DXM around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LHO-I: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for LHO-I: No historical data available for LHO-I around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FTT: possibly delisted; no timezone found\n",
      "$AMIC: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for FTT: No historical data available for FTT around 2024-01-23.\n",
      "Error fetching data for AMIC: No historical data available for AMIC around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AHL-PC: possibly delisted; no price data found  (period=1d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AHL-PC: single positional indexer is out-of-bounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$KWK: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$RT: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for KWK: No historical data available for KWK around 2024-01-23.\n",
      "Error fetching data for RT: No historical data available for RT around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ELU: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ELU: No historical data available for ELU around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HPJ: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HPJ: No historical data available for HPJ around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ISIG: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ISIG: No historical data available for ISIG around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$EOC: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$GPT: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for EOC: No historical data available for EOC around 2024-01-23.\n",
      "Error fetching data for GPT: No historical data available for GPT around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RLGY: possibly delisted; no timezone found\n",
      "$EPIQ: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for RLGY: No historical data available for RLGY around 2024-01-23.\n",
      "Error fetching data for EPIQ: No historical data available for EPIQ around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ACTS: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ACTS: No historical data available for ACTS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BBBY: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BBBY: No historical data available for BBBY around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MXIM: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MXIM: No historical data available for MXIM around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BPY: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BPY: No historical data available for BPY around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AIV-Z: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AIV-Z: No historical data available for AIV-Z around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TCO-K: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TCO-K: No historical data available for TCO-K around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$USB-A: possibly delisted; no timezone found\n",
      "$CAVM: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for USB-A: No historical data available for USB-A around 2024-01-23.\n",
      "Error fetching data for CAVM: No historical data available for CAVM around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JAH: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for JAH: No historical data available for JAH around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TKMR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TKMR: No historical data available for TKMR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RVLT: possibly delisted; no timezone found\n",
      "$FMD: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for RVLT: No historical data available for RVLT around 2024-01-23.\n",
      "Error fetching data for FMD: No historical data available for FMD around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$EDS: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for EDS: No historical data available for EDS around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DW: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DW: No historical data available for DW around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DRE-K: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DRE-K: No historical data available for DRE-K around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NVEEU: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NVEEU: No historical data available for NVEEU around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ABC: possibly delisted; no timezone found\n",
      "$JSN: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ABC: No historical data available for ABC around 2024-01-23.\n",
      "Error fetching data for JSN: No historical data available for JSN around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XGTIW: possibly delisted; no timezone found\n",
      "$BICK: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for XGTIW: No historical data available for XGTIW around 2024-01-23.\n",
      "Error fetching data for BICK: No historical data available for BICK around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ISH: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ISH: No historical data available for ISH around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SWIR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SWIR: No historical data available for SWIR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CADC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CADC: No historical data available for CADC around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$OKSB: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for OKSB: No historical data available for OKSB around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MET-B: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MET-B: No historical data available for MET-B around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ASCA: possibly delisted; no timezone found\n",
      "$NTL: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ASCA: No historical data available for ASCA around 2024-01-23.\n",
      "Error fetching data for NTL: No historical data available for NTL around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$IDT.P: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for IDT.P: No historical data available for IDT.P around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BXS-A: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BXS-A: No historical data available for BXS-A around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MDSO: possibly delisted; no timezone found\n",
      "$ROSG: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$GEVA: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MDSO: No historical data available for MDSO around 2024-01-23.\n",
      "Error fetching data for ROSG: No historical data available for ROSG around 2024-01-23.\n",
      "Error fetching data for GEVA: No historical data available for GEVA around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TLP: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TLP: No historical data available for TLP around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MTT: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MTT: No historical data available for MTT around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XLNX: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for XLNX: No historical data available for XLNX around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$EXD: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for EXD: No historical data available for EXD around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TUES: possibly delisted; no timezone found\n",
      "$MTSN: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TUES: No historical data available for TUES around 2024-01-23.\n",
      "Error fetching data for MTSN: No historical data available for MTSN around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CUB: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23) (Yahoo error = \"Data doesn't exist for startDate = 1703394000, endDate = 1705986000\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CUB: No historical data available for CUB around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LXK: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for LXK: No historical data available for LXK around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LOR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for LOR: No historical data available for LOR around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RTK: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for RTK: No historical data available for RTK around 2024-01-23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ZHNE: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n",
      "$DATE: possibly delisted; no price data found  (1d 2023-12-24 -> 2024-01-23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ZHNE: No historical data available for ZHNE around 2024-01-23.\n",
      "Error fetching data for Date: No historical data available for Date around 2024-01-23.\n",
      "Skipping Date due to insufficient valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CLOSE: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for Close: No historical data available for Close around 2024-01-23.\n",
      "Skipping Close due to insufficient valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VOLUME: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for Volume: No historical data available for Volume around 2024-01-23.\n",
      "Skipping Volume due to insufficient valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DIVIDENDS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for Dividends: No historical data available for Dividends around 2024-01-23.\n",
      "Skipping Dividends due to insufficient valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$STOCK SPLITS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for Stock Splits: No historical data available for Stock Splits around 2024-01-23.\n",
      "Skipping Stock Splits due to insufficient valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FUTURE YEAR CHANGE: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for Future Year Change: No historical data available for Future Year Change around 2024-01-23.\n",
      "Skipping Future Year Change due to insufficient valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$INDUSTRY: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for Industry: No historical data available for Industry around 2024-01-23.\n",
      "Skipping Industry due to insufficient valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'EV/EBIT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "$EV/EBIT: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for EV/EBIT: No historical data available for EV/EBIT around 2024-01-23.\n",
      "Skipping EV/EBIT due to insufficient valid data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gamer\\AppData\\Local\\Temp\\ipykernel_6480\\1893558532.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_test_data = pd.concat(test_data_list, ignore_index=True)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "nan values in `EV/EBIT` but not in setup training set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[235], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid test data collected. Ensure testTickers have valid EV/EBIT and ROIC data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m combinedTestData \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(validTestTickers, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 23\u001b[0m mae, rmse, r2 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluateModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_tickers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombinedTestData\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelFolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcont_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontNames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcat_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatNames\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmount of test tickers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(combinedTestData)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtestSize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mae \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m rmse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m r2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[233], line 21\u001b[0m, in \u001b[0;36mevaluateModel\u001b[1;34m(learn, test_tickers, model_name, model_folder, cont_names, cat_names)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     20\u001b[0m combined_test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(test_data_list, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 21\u001b[0m test_dl \u001b[38;5;241m=\u001b[39m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_test_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m preds, targs \u001b[38;5;241m=\u001b[39m learn\u001b[38;5;241m.\u001b[39mget_preds(dl\u001b[38;5;241m=\u001b[39mtest_dl)\n\u001b[0;32m     23\u001b[0m predictions \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastai\\tabular\\data.py:56\u001b[0m, in \u001b[0;36mTabularDataLoaders.test_dl\u001b[1;34m(self, test_items, rm_type_tfms, process, inplace, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate test `TabDataLoader` from `test_items` using validation `procs`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m to \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_ds\u001b[38;5;241m.\u001b[39mnew(test_items, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process: \u001b[43mto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid\u001b[38;5;241m.\u001b[39mnew(to, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:182\u001b[0m, in \u001b[0;36mTabular.process\u001b[1;34m(self)\u001b[0m\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastcore\\transform.py:210\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, o)\u001b[0m\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompose_tfms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastcore\\transform.py:160\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[1;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[1;32m--> 160\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastcore\\transform.py:83\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencodes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastcore\\transform.py:109\u001b[0m, in \u001b[0;36mInplaceTransform._call\u001b[1;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, x, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastcore\\transform.py:93\u001b[0m, in \u001b[0;36mTransform._call\u001b[1;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, x, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_idx\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastcore\\transform.py:99\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[1;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, x, ret)\n\u001b[0;32m    100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastcore\\dispatch.py:122\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner)\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gamer\\miniconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:312\u001b[0m, in \u001b[0;36mFillMissing.encodes\u001b[1;34m(self, to)\u001b[0m\n\u001b[0;32m    310\u001b[0m missing \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39misnull(to\u001b[38;5;241m.\u001b[39mconts)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m missing\u001b[38;5;241m.\u001b[39many()[missing\u001b[38;5;241m.\u001b[39many()]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_dict, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan values in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` but not in setup training set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    314\u001b[0m     to[n]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mna_dict[n], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: nan values in `EV/EBIT` but not in setup training set"
     ]
    }
   ],
   "source": [
    "if trainNewModel:\n",
    "    nonTrainingTickers = list(set(tickers) - set(trainingTickers))\n",
    "    randomNonTrainingTickers = np.random.choice(nonTrainingTickers, size=len(nonTrainingTickers), replace=False).tolist()\n",
    "    \n",
    "#randomNonTrainingTickers = np.random.choice(nonTrainingTickers, size=min(testSize, len(nonTrainingTickers)), replace=False).tolist()\n",
    "\n",
    "    # Filter out test tickers with NaN EV/EBIT or NaN ROIC\n",
    "    validTestTickers = []\n",
    "    i = 0\n",
    "    while i < testSize:\n",
    "        testData = getTickerDataFrom1YrAgo(randomNonTrainingTickers[i])\n",
    "        if testData.empty or testData[['EV/EBIT', 'ROIC']].isna().any().any():\n",
    "            pass\n",
    "        else:\n",
    "            validTestTickers.append(testData)\n",
    "        i += 1\n",
    "\n",
    "    if not validTestTickers:\n",
    "        raise ValueError(\"No valid test data collected. Ensure testTickers have valid EV/EBIT and ROIC data.\")\n",
    "\n",
    "    combinedTestData = pd.concat(validTestTickers, ignore_index=True)\n",
    "\n",
    "    mae, rmse, r2 = evaluateModel(\n",
    "        learn=learn,\n",
    "        test_tickers=combinedTestData,\n",
    "        model_name=modelName,\n",
    "        model_folder=modelFolder,\n",
    "        cont_names=contNames,\n",
    "        cat_names=catNames\n",
    "    )\n",
    "    \n",
    "    print(f\"Amount of test tickers: {len(combinedTestData)}, Expected: {testSize}\")\n",
    "\n",
    "    if mae is not None and rmse is not None and r2 is not None:\n",
    "        print(f\"Evaluation Results:\")\n",
    "        print(f\"MAE: {mae:.3f}\")\n",
    "        print(f\"RMSE: {rmse:.3f}\")\n",
    "        print(f\"R2: {r2:.3f}\")\n",
    "    else:\n",
    "        print(\"Evaluation failed. Metrics are None.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model files in modelFolder:\n",
      "stockScreenerV1.0.pkl\n",
      "stockScreenerV2.0.pkl\n",
      "stockScreenerV3.0.pkl\n",
      "stockScreenerV4.0.pkl\n",
      "stockScreenerV4.1.pkl\n",
      "stockScreenerV5.0.pkl\n",
      "stockScreenerV5.1.pkl\n",
      "stockScreenerV5.2.pkl\n",
      "stockScreenerV5.3.pkl\n",
      "stockScreenerV5.4.pkl\n",
      "stockScreenerV6.0.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Model files in modelFolder:')\n",
    "for file in modelFolder.glob('*.pkl'):\n",
    "    print(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name    stockScreenerV5.0\n",
       "Timestamp      2025-01-21 21:03\n",
       "MAE                       0.237\n",
       "RMSE                      0.302\n",
       "R2                       -0.002\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations = pd.read_csv(modelFolder / 'modelEvaluations.csv')\n",
    "bestModel = evaluations.sort_values('MAE', ascending=True).iloc[0]\n",
    "bestModel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "importedModel = Path(f\"{bestModel['Model Name']}.pkl\") # Change this if you want to try other models\n",
    "learn = load_learner(modelFolder / importedModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for NVO (Novo Nordisk A/S):\n",
      "41.37%\n",
      "Free money?!\n"
     ]
    }
   ],
   "source": [
    "if predictionTarget != 'None':\n",
    "    if predictionTarget == 'ALL':\n",
    "        predictionTickers = tickers\n",
    "    elif predictionTarget.endswith('%'):\n",
    "        percentage = float(predictionTarget.strip('%')) / 100\n",
    "        num_tickers = int(len(tickers) * percentage)\n",
    "        predictionTickers = np.random.choice(tickers, size=num_tickers, replace=False).tolist()\n",
    "    else:\n",
    "        predictionTickers = [predictionTarget]\n",
    "\n",
    "    # Fetch data for prediction tickers\n",
    "    dfPrediction = pd.concat([getTickerData(ticker) for ticker in predictionTickers], ignore_index=True)\n",
    "\n",
    "    # Ensure dfPrediction is a DataFrame\n",
    "    if isinstance(dfPrediction, dict):\n",
    "        dfPrediction = pd.DataFrame([dfPrediction])\n",
    "\n",
    "    # Create test dataloader\n",
    "    dl = learn.dls.test_dl(dfPrediction)\n",
    "    dfPrediction.head()\n",
    "\n",
    "    # Make predictions\n",
    "    prediction = learn.get_preds(dl=dl)\n",
    "    adr_df = pd.read_csv(testFolder / 'tickers.csv')\n",
    "    company_dict = dict(zip(adr_df['Ticker'], adr_df['Company']))\n",
    "\n",
    "    if predictionTarget == 'ALL' or predictionTarget.endswith('%'):\n",
    "        sorted_predictions = sorted(zip(predictionTickers, prediction[0]), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"Got predictions for {len(sorted_predictions)} tickers, expected: {len(predictionTickers)}\")\n",
    "        print(f\"Prediction for best performing tickers:\")\n",
    "        for symbol, pred in sorted_predictions:\n",
    "            company_name = company_dict.get(symbol, 'Unknown')\n",
    "            print(f\"{symbol} ({company_name}): {pred[0].item() * 100:.2f}%\")\n",
    "    else:\n",
    "        company_name = company_dict.get(predictionTarget, 'Unknown')\n",
    "        print(f\"Prediction for {predictionTarget} ({company_name}):\")\n",
    "        print(f\"{prediction[0][0][0].item() * 100:.2f}%\")\n",
    "    print(\"Free money?!\")\n",
    "\n",
    "predictionTarget = '8%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
