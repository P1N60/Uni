{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries on first run\n",
    "#! pip install -q ipynb fastai pathlib pandas import_ipynb numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'stockScreenerV3.0'\n",
    "trainingDataName = 'stockData.csv'\n",
    "trainingFolder = Path.cwd().parent / 'TrainingData'\n",
    "modelFolder = Path.cwd().parent.parent / 'TrainedModels'\n",
    "testFolder = Path.cwd().parent / 'TestData'\n",
    "\n",
    "# Training parameters\n",
    "yNames = ['Future Year Change']\n",
    "catNames = ['Industry']\n",
    "contNames = [\n",
    "    'Open',\n",
    "    'High', \n",
    "    'Low', \n",
    "    'Close', \n",
    "    'Volume', \n",
    "    'Dividends', \n",
    "    'Stock Splits', \n",
    "    'EV/EBIT', \n",
    "    'ROIC'\n",
    "]\n",
    "epochs = 2\n",
    "\n",
    "# Test parameters\n",
    "testSize = 100 # Number of stocks to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can have a look at how the data is structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Future Year Change</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Capital Gains</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>ROIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-20 00:00:00-04:00</td>\n",
       "      <td>16.25</td>\n",
       "      <td>16.990</td>\n",
       "      <td>14.00</td>\n",
       "      <td>16.26</td>\n",
       "      <td>37563700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.194342</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.190711</td>\n",
       "      <td>0.360613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-23 00:00:00-04:00</td>\n",
       "      <td>16.10</td>\n",
       "      <td>16.399</td>\n",
       "      <td>15.12</td>\n",
       "      <td>15.26</td>\n",
       "      <td>5753800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.145478</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.963060</td>\n",
       "      <td>0.402433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-24 00:00:00-04:00</td>\n",
       "      <td>15.40</td>\n",
       "      <td>15.860</td>\n",
       "      <td>14.77</td>\n",
       "      <td>15.24</td>\n",
       "      <td>3748300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.179134</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.958507</td>\n",
       "      <td>0.403368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-25 00:00:00-04:00</td>\n",
       "      <td>15.10</td>\n",
       "      <td>15.430</td>\n",
       "      <td>13.62</td>\n",
       "      <td>13.73</td>\n",
       "      <td>4408100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.071377</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.614754</td>\n",
       "      <td>0.489238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-26 00:00:00-04:00</td>\n",
       "      <td>13.82</td>\n",
       "      <td>14.160</td>\n",
       "      <td>13.81</td>\n",
       "      <td>14.02</td>\n",
       "      <td>1850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.099857</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.680773</td>\n",
       "      <td>0.470022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date   Open    High    Low  Close      Volume  \\\n",
       "0  2017-10-20 00:00:00-04:00  16.25  16.990  14.00  16.26  37563700.0   \n",
       "1  2017-10-23 00:00:00-04:00  16.10  16.399  15.12  15.26   5753800.0   \n",
       "2  2017-10-24 00:00:00-04:00  15.40  15.860  14.77  15.24   3748300.0   \n",
       "3  2017-10-25 00:00:00-04:00  15.10  15.430  13.62  13.73   4408100.0   \n",
       "4  2017-10-26 00:00:00-04:00  13.82  14.160  13.81  14.02   1850000.0   \n",
       "\n",
       "   Dividends  Stock Splits  Future Year Change Ticker         Industry  \\\n",
       "0        0.0           0.0           -0.194342     SE  Internet Retail   \n",
       "1        0.0           0.0           -0.145478     SE  Internet Retail   \n",
       "2        0.0           0.0           -0.179134     SE  Internet Retail   \n",
       "3        0.0           0.0           -0.071377     SE  Internet Retail   \n",
       "4        0.0           0.0           -0.099857     SE  Internet Retail   \n",
       "\n",
       "   Adj Close  Capital Gains   EV/EBIT      ROIC  \n",
       "0        NaN            NaN  2.190711  0.360613  \n",
       "1        NaN            NaN  1.963060  0.402433  \n",
       "2        NaN            NaN  1.958507  0.403368  \n",
       "3        NaN            NaN  1.614754  0.489238  \n",
       "4        NaN            NaN  1.680773  0.470022  "
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPath = Path()\n",
    "df = pd.read_csv(trainingFolder/trainingDataName)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns are continuous (like age) and we will treat them as float numbers we can feed our model directly. Others are categorical (like workclass or education) and we will convert them to a unique index that we will feed to embedding layers. We can specify our categorical and continuous column names, as well as the name of the dependent variable in TabularDataLoaders factory methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dls = TabularDataLoaders.from_csv(trainingFolder/trainingDataName, path=dataPath, \n",
    "    y_names=yNames,\n",
    "    cat_names=catNames,\n",
    "    cont_names=contNames,\n",
    "    procs = [Categorify, FillMissing, Normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part is the list of pre-processors we apply to our data:\n",
    "\n",
    "* Categorify is going to take every categorical variable and make a map from integer to unique categories, then replace the values by the corresponding index.\n",
    "* FillMissing will fill the missing values in the continuous variables by the median of existing values (you can choose a specific value if you prefer)\n",
    "* Normalize will normalize the continuous variables (subtract the mean and divide by the std)\n",
    "\n",
    "To further expose what’s going on below the surface, let’s rewrite this utilizing fastai’s TabularPandas class. We will need to make one adjustment, which is defining how we want to split our data. By default the factory method above used a random 80/20 split, so we will do the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = EndSplitter (valid_pct=0.2, valid_last=True)(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "to = TabularPandas(df, procs=[Categorify, FillMissing, Normalize],\n",
    "    y_names=yNames,\n",
    "    cat_names = catNames,\n",
    "    cont_names = contNames,\n",
    "    splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we build our TabularPandas object, our data is completely preprocessed as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>EV/EBIT_na</th>\n",
       "      <th>ROIC_na</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>ROIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.161926</td>\n",
       "      <td>-0.157894</td>\n",
       "      <td>-0.183005</td>\n",
       "      <td>-0.162741</td>\n",
       "      <td>5.635154</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.19608</td>\n",
       "      <td>-0.085114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Industry  EV/EBIT_na  ROIC_na      Open      High       Low     Close  \\\n",
       "0        23           1        1 -0.161926 -0.157894 -0.183005 -0.162741   \n",
       "\n",
       "     Volume  Dividends  Stock Splits  EV/EBIT      ROIC  \n",
       "0  5.635154  -0.050866     -0.013349 -0.19608 -0.085114  "
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.xs.iloc[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build our DataLoaders again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The show_batch method works like for every other application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>EV/EBIT_na</th>\n",
       "      <th>ROIC_na</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>ROIC</th>\n",
       "      <th>Future Year Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Software - Application</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65.290001</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>64.157998</td>\n",
       "      <td>65.769997</td>\n",
       "      <td>3.076500e+06</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>14.217635</td>\n",
       "      <td>0.055565</td>\n",
       "      <td>7.165122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auto Manufacturers</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.537457</td>\n",
       "      <td>5.643947</td>\n",
       "      <td>5.537457</td>\n",
       "      <td>5.601350</td>\n",
       "      <td>2.159996e+04</td>\n",
       "      <td>3.500000e-02</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>1.810714</td>\n",
       "      <td>0.436292</td>\n",
       "      <td>0.536588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gold</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.405805</td>\n",
       "      <td>4.405807</td>\n",
       "      <td>4.048579</td>\n",
       "      <td>4.048578</td>\n",
       "      <td>9.099856e+03</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>4.829698</td>\n",
       "      <td>0.163571</td>\n",
       "      <td>0.161765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consumer Electronics</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.233453</td>\n",
       "      <td>0.233451</td>\n",
       "      <td>0.225399</td>\n",
       "      <td>0.233451</td>\n",
       "      <td>2.188999e+05</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>1.663136</td>\n",
       "      <td>0.475006</td>\n",
       "      <td>0.137930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drug Manufacturers - Specialty &amp; Generic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29.278507</td>\n",
       "      <td>29.690546</td>\n",
       "      <td>29.270582</td>\n",
       "      <td>29.484526</td>\n",
       "      <td>4.018100e+06</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>19.621371</td>\n",
       "      <td>0.040262</td>\n",
       "      <td>0.263167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Telecom Services</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11.423454</td>\n",
       "      <td>11.492115</td>\n",
       "      <td>11.350502</td>\n",
       "      <td>11.483532</td>\n",
       "      <td>5.185664e+06</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>13.312311</td>\n",
       "      <td>0.059343</td>\n",
       "      <td>0.140201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Specialty Business Services</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.162026</td>\n",
       "      <td>3.162027</td>\n",
       "      <td>3.081358</td>\n",
       "      <td>3.081361</td>\n",
       "      <td>1.239997e+04</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>8.982103</td>\n",
       "      <td>0.087953</td>\n",
       "      <td>0.366325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Banks - Diversified</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9.457927</td>\n",
       "      <td>9.591164</td>\n",
       "      <td>9.383907</td>\n",
       "      <td>9.395012</td>\n",
       "      <td>1.272001e+05</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>1.166495</td>\n",
       "      <td>0.677243</td>\n",
       "      <td>0.145915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Software - Application</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.090002</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>3.045000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>1.115070e+07</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>16.430627</td>\n",
       "      <td>0.048082</td>\n",
       "      <td>0.329032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oil &amp; Gas Equipment &amp; Services</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>46.898960</td>\n",
       "      <td>48.029057</td>\n",
       "      <td>46.750637</td>\n",
       "      <td>47.923107</td>\n",
       "      <td>1.196190e+07</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>14.110963</td>\n",
       "      <td>0.055984</td>\n",
       "      <td>0.265190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a model using the tabular_learner method. When we define our model, fastai will try to infer the loss function based on our y_names earlier.\n",
    "\n",
    "Note: Sometimes with tabular data, your y’s may be encoded (such as 0 and 1). In such a case you should explicitly pass y_block = CategoryBlock in your constructor so fastai won’t presume you are doing regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=[rmse, mae])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can train that model with the fit_one_cycle method (the fine_tune method won’t be useful here since we don’t have a pretrained model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stockScreenerV3.0 for 2 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.458944</td>\n",
       "      <td>110645.234375</td>\n",
       "      <td>332.634064</td>\n",
       "      <td>5.322650</td>\n",
       "      <td>01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.706610</td>\n",
       "      <td>22672816.000000</td>\n",
       "      <td>4761.597656</td>\n",
       "      <td>70.884811</td>\n",
       "      <td>01:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Training {modelName} for {epochs} epochs\")\n",
    "learn.fit_one_cycle(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then have a look at some training predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>EV/EBIT_na</th>\n",
       "      <th>ROIC_na</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>ROIC</th>\n",
       "      <th>Future Year Change</th>\n",
       "      <th>Future Year Change_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.390352</td>\n",
       "      <td>0.387230</td>\n",
       "      <td>0.393953</td>\n",
       "      <td>0.392971</td>\n",
       "      <td>-0.404855</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.145133</td>\n",
       "      <td>-0.086208</td>\n",
       "      <td>0.011517</td>\n",
       "      <td>0.207719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.262461</td>\n",
       "      <td>-0.264234</td>\n",
       "      <td>-0.263215</td>\n",
       "      <td>-0.263305</td>\n",
       "      <td>3.863284</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.139208</td>\n",
       "      <td>-0.087680</td>\n",
       "      <td>-0.108092</td>\n",
       "      <td>-0.050459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.288135</td>\n",
       "      <td>-0.289057</td>\n",
       "      <td>-0.288154</td>\n",
       "      <td>-0.288723</td>\n",
       "      <td>-0.503011</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.373120</td>\n",
       "      <td>-0.087961</td>\n",
       "      <td>0.141655</td>\n",
       "      <td>0.103646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.278466</td>\n",
       "      <td>-0.280291</td>\n",
       "      <td>-0.278849</td>\n",
       "      <td>-0.279571</td>\n",
       "      <td>-0.023821</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>-0.087378</td>\n",
       "      <td>0.431009</td>\n",
       "      <td>0.134975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.221172</td>\n",
       "      <td>-0.222126</td>\n",
       "      <td>-0.221494</td>\n",
       "      <td>-0.220542</td>\n",
       "      <td>0.655362</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.005178</td>\n",
       "      <td>-0.087284</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>0.352113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.281279</td>\n",
       "      <td>-0.282771</td>\n",
       "      <td>-0.281292</td>\n",
       "      <td>-0.282035</td>\n",
       "      <td>-0.125137</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>-0.087310</td>\n",
       "      <td>-0.469636</td>\n",
       "      <td>0.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.290506</td>\n",
       "      <td>-0.289142</td>\n",
       "      <td>-0.290553</td>\n",
       "      <td>-0.288182</td>\n",
       "      <td>-0.505915</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.073023</td>\n",
       "      <td>-0.087536</td>\n",
       "      <td>1.227273</td>\n",
       "      <td>0.207363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.286985</td>\n",
       "      <td>-0.288656</td>\n",
       "      <td>-0.288184</td>\n",
       "      <td>-0.288673</td>\n",
       "      <td>0.213455</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.073078</td>\n",
       "      <td>-0.086926</td>\n",
       "      <td>0.910113</td>\n",
       "      <td>0.066598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.265556</td>\n",
       "      <td>-0.266046</td>\n",
       "      <td>-0.266835</td>\n",
       "      <td>-0.266474</td>\n",
       "      <td>2.780753</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.094034</td>\n",
       "      <td>-0.086769</td>\n",
       "      <td>0.857711</td>\n",
       "      <td>0.355706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.666928</td>\n",
       "      <td>2.796943</td>\n",
       "      <td>2.691123</td>\n",
       "      <td>2.798673</td>\n",
       "      <td>-0.203024</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>4.011590</td>\n",
       "      <td>-0.088410</td>\n",
       "      <td>0.250856</td>\n",
       "      <td>-0.101249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.172305</td>\n",
       "      <td>0.180968</td>\n",
       "      <td>0.177650</td>\n",
       "      <td>0.185963</td>\n",
       "      <td>-0.130614</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.250910</td>\n",
       "      <td>-0.087844</td>\n",
       "      <td>0.167754</td>\n",
       "      <td>0.127681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.290875</td>\n",
       "      <td>-0.292699</td>\n",
       "      <td>-0.291235</td>\n",
       "      <td>-0.292082</td>\n",
       "      <td>-0.504997</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.356350</td>\n",
       "      <td>-0.087948</td>\n",
       "      <td>0.361622</td>\n",
       "      <td>0.101820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.319578</td>\n",
       "      <td>-0.321093</td>\n",
       "      <td>-0.319964</td>\n",
       "      <td>-0.320477</td>\n",
       "      <td>-0.506203</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>-0.087922</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.113058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.801547</td>\n",
       "      <td>0.790889</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.798566</td>\n",
       "      <td>-0.464889</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.144758</td>\n",
       "      <td>-0.086214</td>\n",
       "      <td>0.151689</td>\n",
       "      <td>0.276091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.285862</td>\n",
       "      <td>-0.287667</td>\n",
       "      <td>-0.285928</td>\n",
       "      <td>-0.286836</td>\n",
       "      <td>-0.504896</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.247880</td>\n",
       "      <td>-0.081909</td>\n",
       "      <td>0.048697</td>\n",
       "      <td>0.274792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stockFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HRL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$NTR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HRL: No historical data available for HRL around 2024-01-21.\n",
      "Skipping HRL due to missing data\n",
      "Error fetching data for NTR: No historical data available for NTR around 2024-01-21.\n",
      "Skipping NTR due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AMTD: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$BEPC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$DB: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AMTD: No historical data available for AMTD around 2024-01-21.\n",
      "Skipping AMTD due to missing data\n",
      "Error fetching data for BEPC: No historical data available for BEPC around 2024-01-21.\n",
      "Skipping BEPC due to missing data\n",
      "Error fetching data for DB: No historical data available for DB around 2024-01-21.\n",
      "Skipping DB due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$ZS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PM: No historical data available for PM around 2024-01-21.\n",
      "Skipping PM due to missing data\n",
      "Error fetching data for ZS: No historical data available for ZS around 2024-01-21.\n",
      "Skipping ZS due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$EXPI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for EXPI: No historical data available for EXPI around 2024-01-21.\n",
      "Skipping EXPI due to missing data\n",
      "Error fetching data for TM: No historical data available for TM around 2024-01-21.\n",
      "Skipping TM due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TRGP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$SAP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TRGP: No historical data available for TRGP around 2024-01-21.\n",
      "Skipping TRGP due to missing data\n",
      "Error fetching data for SAP: No historical data available for SAP around 2024-01-21.\n",
      "Skipping SAP due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MOS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$AGI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TAL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$WIX: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MOS: No historical data available for MOS around 2024-01-21.\n",
      "Skipping MOS due to missing data\n",
      "Error fetching data for AGI: No historical data available for AGI around 2024-01-21.\n",
      "Skipping AGI due to missing data\n",
      "Error fetching data for TAL: No historical data available for TAL around 2024-01-21.\n",
      "Skipping TAL due to missing data\n",
      "Error fetching data for WIX: No historical data available for WIX around 2024-01-21.\n",
      "Skipping WIX due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$EOG: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$RACE: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for EOG: No historical data available for EOG around 2024-01-21.\n",
      "Skipping EOG due to missing data\n",
      "Error fetching data for RACE: No historical data available for RACE around 2024-01-21.\n",
      "Skipping RACE due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AXP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$AFRM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AXP: No historical data available for AXP around 2024-01-21.\n",
      "Skipping AXP due to missing data\n",
      "Error fetching data for AFRM: No historical data available for AFRM around 2024-01-21.\n",
      "Skipping AFRM due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SCHW: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$MO: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SCHW: No historical data available for SCHW around 2024-01-21.\n",
      "Skipping SCHW due to missing data\n",
      "Error fetching data for MO: No historical data available for MO around 2024-01-21.\n",
      "Skipping MO due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VIPS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$ITUB: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$BBVA: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for VIPS: No historical data available for VIPS around 2024-01-21.\n",
      "Skipping VIPS due to missing data\n",
      "Error fetching data for ITUB: No historical data available for ITUB around 2024-01-21.\n",
      "Skipping ITUB due to missing data\n",
      "Error fetching data for BBVA: No historical data available for BBVA around 2024-01-21.\n",
      "Skipping BBVA due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SQM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$RUN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$CF: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SQM: No historical data available for SQM around 2024-01-21.\n",
      "Skipping SQM due to missing data\n",
      "Error fetching data for RUN: No historical data available for RUN around 2024-01-21.\n",
      "Skipping RUN due to missing data\n",
      "Error fetching data for CF: No historical data available for CF around 2024-01-21.\n",
      "Skipping CF due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$KGC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TSN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for KGC: No historical data available for KGC around 2024-01-21.\n",
      "Skipping KGC due to missing data\n",
      "Error fetching data for TSN: No historical data available for TSN around 2024-01-21.\n",
      "Skipping TSN due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PKX: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$BTI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PKX: No historical data available for PKX around 2024-01-21.\n",
      "Skipping PKX due to missing data\n",
      "Error fetching data for BTI: No historical data available for BTI around 2024-01-21.\n",
      "Skipping BTI due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ENIC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$CME: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$CSIQ: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$GFL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$DASH: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ENIC: No historical data available for ENIC around 2024-01-21.\n",
      "Skipping ENIC due to missing data\n",
      "Error fetching data for CME: No historical data available for CME around 2024-01-21.\n",
      "Skipping CME due to missing data\n",
      "Error fetching data for CSIQ: No historical data available for CSIQ around 2024-01-21.\n",
      "Skipping CSIQ due to missing data\n",
      "Error fetching data for GFL: No historical data available for GFL around 2024-01-21.\n",
      "Skipping GFL due to missing data\n",
      "Error fetching data for DASH: No historical data available for DASH around 2024-01-21.\n",
      "Skipping DASH due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$IPI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BP: No historical data available for BP around 2024-01-21.\n",
      "Skipping BP due to missing data\n",
      "Error fetching data for IPI: No historical data available for IPI around 2024-01-21.\n",
      "Skipping IPI due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RLI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$RNR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for RLI: No historical data available for RLI around 2024-01-21.\n",
      "Skipping RLI due to missing data\n",
      "Error fetching data for RNR: No historical data available for RNR around 2024-01-21.\n",
      "Skipping RNR due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LAC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$EL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$MSCI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for LAC: No historical data available for LAC around 2024-01-21.\n",
      "Skipping LAC due to missing data\n",
      "Error fetching data for EL: No historical data available for EL around 2024-01-21.\n",
      "Skipping EL due to missing data\n",
      "Error fetching data for MSCI: No historical data available for MSCI around 2024-01-21.\n",
      "Skipping MSCI due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MT: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$DDOG: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$VLO: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MT: No historical data available for MT around 2024-01-21.\n",
      "Skipping MT due to missing data\n",
      "Error fetching data for DDOG: No historical data available for DDOG around 2024-01-21.\n",
      "Skipping DDOG due to missing data\n",
      "Error fetching data for VLO: No historical data available for VLO around 2024-01-21.\n",
      "Skipping VLO due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HBAN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$COP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HBAN: No historical data available for HBAN around 2024-01-21.\n",
      "Skipping HBAN due to missing data\n",
      "Error fetching data for COP: No historical data available for COP around 2024-01-21.\n",
      "Skipping COP due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MKTX: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$PAAS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$NTDOY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MKTX: No historical data available for MKTX around 2024-01-21.\n",
      "Skipping MKTX due to missing data\n",
      "Error fetching data for PAAS: No historical data available for PAAS around 2024-01-21.\n",
      "Skipping PAAS due to missing data\n",
      "Error fetching data for NTDOY: No historical data available for NTDOY around 2024-01-21.\n",
      "Skipping NTDOY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HMC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$SPGI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HMC: No historical data available for HMC around 2024-01-21.\n",
      "Skipping HMC due to missing data\n",
      "Error fetching data for SPGI: No historical data available for SPGI around 2024-01-21.\n",
      "Skipping SPGI due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MFG: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$SOFI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$AMT: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MFG: No historical data available for MFG around 2024-01-21.\n",
      "Skipping MFG due to missing data\n",
      "Error fetching data for SOFI: No historical data available for SOFI around 2024-01-21.\n",
      "Skipping SOFI due to missing data\n",
      "Error fetching data for AMT: No historical data available for AMT around 2024-01-21.\n",
      "Skipping AMT due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GFI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$LC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$DLR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GFI: No historical data available for GFI around 2024-01-21.\n",
      "Skipping GFI due to missing data\n",
      "Error fetching data for LC: No historical data available for LC around 2024-01-21.\n",
      "Skipping LC due to missing data\n",
      "Error fetching data for DLR: No historical data available for DLR around 2024-01-21.\n",
      "Skipping DLR due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CBAUF: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TWLO: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$VOD: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CBAUF: No historical data available for CBAUF around 2024-01-21.\n",
      "Skipping CBAUF due to missing data\n",
      "Error fetching data for TWLO: No historical data available for TWLO around 2024-01-21.\n",
      "Skipping TWLO due to missing data\n",
      "Error fetching data for VOD: No historical data available for VOD around 2024-01-21.\n",
      "Skipping VOD due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BLDP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TECK: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BLDP: No historical data available for BLDP around 2024-01-21.\n",
      "Skipping BLDP due to missing data\n",
      "Error fetching data for TECK: No historical data available for TECK around 2024-01-21.\n",
      "Skipping TECK due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RELX: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$IMBBY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for RELX: No historical data available for RELX around 2024-01-21.\n",
      "Skipping RELX due to missing data\n",
      "Error fetching data for IMBBY: No historical data available for IMBBY around 2024-01-21.\n",
      "Skipping IMBBY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PNC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$KEY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PNC: No historical data available for PNC around 2024-01-21.\n",
      "Skipping PNC due to missing data\n",
      "Error fetching data for KEY: No historical data available for KEY around 2024-01-21.\n",
      "Skipping KEY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$IBKR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$ATHM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$NOW: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for IBKR: No historical data available for IBKR around 2024-01-21.\n",
      "Skipping IBKR due to missing data\n",
      "Error fetching data for ATHM: No historical data available for ATHM around 2024-01-21.\n",
      "Skipping ATHM due to missing data\n",
      "Error fetching data for NOW: No historical data available for NOW around 2024-01-21.\n",
      "Skipping NOW due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SPWR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SPWR: No historical data available for SPWR around 2024-01-21.\n",
      "Skipping SPWR due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NESN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NESN: No historical data available for NESN around 2024-01-21.\n",
      "Skipping NESN due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XOM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TFC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for XOM: No historical data available for XOM around 2024-01-21.\n",
      "Skipping XOM due to missing data\n",
      "Error fetching data for TFC: No historical data available for TFC around 2024-01-21.\n",
      "Skipping TFC due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CVX: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$BABA: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$EQIX: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CVX: No historical data available for CVX around 2024-01-21.\n",
      "Skipping CVX due to missing data\n",
      "Error fetching data for BABA: No historical data available for BABA around 2024-01-21.\n",
      "Skipping BABA due to missing data\n",
      "Error fetching data for EQIX: No historical data available for EQIX around 2024-01-21.\n",
      "Skipping EQIX due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$COF: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$EDU: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$AM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for COF: No historical data available for COF around 2024-01-21.\n",
      "Skipping COF due to missing data\n",
      "Error fetching data for EDU: No historical data available for EDU around 2024-01-21.\n",
      "Skipping EDU due to missing data\n",
      "Error fetching data for AM: No historical data available for AM around 2024-01-21.\n",
      "Skipping AM due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SLB: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$BK: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SLB: No historical data available for SLB around 2024-01-21.\n",
      "Skipping SLB due to missing data\n",
      "Error fetching data for BK: No historical data available for BK around 2024-01-21.\n",
      "Skipping BK due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FANUY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for FANUY: No historical data available for FANUY around 2024-01-21.\n",
      "Skipping FANUY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SPLK: possibly delisted; no timezone found\n",
      "$HIG: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SPLK: No historical data available for SPLK around 2024-01-21.\n",
      "Skipping SPLK due to missing data\n",
      "Error fetching data for HIG: No historical data available for HIG around 2024-01-21.\n",
      "Skipping HIG due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WMB: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$DSY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$YY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for WMB: No historical data available for WMB around 2024-01-21.\n",
      "Skipping WMB due to missing data\n",
      "Error fetching data for DSY: No historical data available for DSY around 2024-01-21.\n",
      "Skipping DSY due to missing data\n",
      "Error fetching data for YY: No historical data available for YY around 2024-01-21.\n",
      "Skipping YY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RDS.A: possibly delisted; no timezone found\n",
      "$ERIC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for RDS.A: No historical data available for RDS.A around 2024-01-21.\n",
      "Skipping RDS.A due to missing data\n",
      "Error fetching data for ERIC: No historical data available for ERIC around 2024-01-21.\n",
      "Skipping ERIC due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$OKE: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$STT: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for OKE: No historical data available for OKE around 2024-01-21.\n",
      "Skipping OKE due to missing data\n",
      "Error fetching data for STT: No historical data available for STT around 2024-01-21.\n",
      "Skipping STT due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SAN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$NTTYY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SAN: No historical data available for SAN around 2024-01-21.\n",
      "Skipping SAN due to missing data\n",
      "Error fetching data for NTTYY: No historical data available for NTTYY around 2024-01-21.\n",
      "Skipping NTTYY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PLUG: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$ING: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$RDFN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for PLUG: No historical data available for PLUG around 2024-01-21.\n",
      "Skipping PLUG due to missing data\n",
      "Error fetching data for ING: No historical data available for ING around 2024-01-21.\n",
      "Skipping ING due to missing data\n",
      "Error fetching data for RDFN: No historical data available for RDFN around 2024-01-21.\n",
      "Skipping RDFN due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$UL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$VRSK: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for UL: No historical data available for UL around 2024-01-21.\n",
      "Skipping UL due to missing data\n",
      "Error fetching data for VRSK: No historical data available for VRSK around 2024-01-21.\n",
      "Skipping VRSK due to missing data\n",
      "No valid test data collected\n",
      "Evaluation failed. Metrics are None.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(learn, test_tickers, model_name, model_folder, cont_names, cat_names):\n",
    "    \"\"\"\n",
    "    Evaluate a fastai model on a list of test tickers and log the results.\n",
    "    \n",
    "    Args:\n",
    "        learn: fastai Learner object\n",
    "        test_tickers (list): List of ticker symbols to test on\n",
    "        model_name (str): Name of the model for logging\n",
    "        model_folder (Path): Path to save evaluation results\n",
    "        cont_names (list): List of continuous feature names\n",
    "        cat_names (list): List of categorical feature names\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "    test_data_list = []\n",
    "    \n",
    "    # Collect test data for all tickers\n",
    "    for ticker in test_tickers:\n",
    "        try:\n",
    "            # Get test data\n",
    "            test_data = stockFetcher.getTickerDataFrom1YrAgo(ticker)\n",
    "            if test_data.empty:\n",
    "                print(f\"Skipping {ticker} due to missing data\")\n",
    "                continue\n",
    "            \n",
    "            test_data_list.append(test_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not test_data_list:\n",
    "        print(\"No valid test data collected\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Combine all test data\n",
    "    combined_test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "    \n",
    "    # Create fastai test dataloader\n",
    "    test_dl = learn.dls.test_dl(combined_test_data)\n",
    "    \n",
    "    # Get predictions\n",
    "    preds, targs = learn.get_preds(dl=test_dl)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    predictions = preds.numpy()\n",
    "    actuals = targs.numpy()\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'Predicted': predictions.flatten(),\n",
    "        'Actual': actuals.flatten()\n",
    "    })\n",
    "\n",
    "    # Calculate residuals\n",
    "    results_df['Residual'] = results_df['Actual'] - results_df['Predicted']\n",
    "\n",
    "    # Define outlier threshold (2 standard deviations)\n",
    "    outlier_threshold = 2 * results_df['Residual'].std()\n",
    "\n",
    "    # Filter outliers\n",
    "    filtered_df = results_df[abs(results_df['Residual']) <= outlier_threshold]\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(filtered_df['Residual']))\n",
    "    rmse = np.sqrt(np.mean(filtered_df['Residual']**2))\n",
    "    r2 = 1 - (np.sum(filtered_df['Residual']**2) / \n",
    "              np.sum((filtered_df['Actual'] - filtered_df['Actual'].mean())**2))\n",
    "\n",
    "    # Log results\n",
    "    log_evaluation(model_name, mae, rmse, r2, model_folder)\n",
    "    \n",
    "    # Create visualizations\n",
    "    plot_results(filtered_df, model_name, model_folder)\n",
    "    \n",
    "    return mae, rmse, r2\n",
    "\n",
    "def log_evaluation(model_name, mae, rmse, r2, model_folder):\n",
    "    \"\"\"Log evaluation metrics to CSV file\"\"\"\n",
    "    log_file = model_folder / \"modelEvaluations.csv\"\n",
    "    \n",
    "    new_entry_df = pd.DataFrame([{\n",
    "        \"Model Name\": modelName,\n",
    "        \"Timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "        \"MAE\": f'{mae:.3f}',\n",
    "        \"RMSE\": f'{rmse:.3f}',\n",
    "        \"R2\": f'{r2:.3f}',\n",
    "        \"Epochs\": epochs,\n",
    "        \"Test Amount\": len(get_random_test_tickers(n_tickers=testSize)),\n",
    "        \"Cat Names\": catNames,\n",
    "        \"Cont Names\": contNames,\n",
    "    }])\n",
    "    \n",
    "    try:\n",
    "        log_df = pd.read_csv(log_file)\n",
    "        log_df = pd.concat([log_df, new_entry_df], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        log_df = new_entry_df\n",
    "        \n",
    "    log_df.to_csv(log_file, index=False)\n",
    "    print(f\"Logged evaluation results to {log_file}\")\n",
    "\n",
    "def plot_results(filtered_df, model_name, model_folder):\n",
    "    \"\"\"Create and save visualization plots\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    actuals = filtered_df['Actual']\n",
    "    predictions = filtered_df['Predicted']\n",
    "    plt.scatter(actuals, predictions, alpha=0.7, label='Predictions')\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(actuals.min(), predictions.min())\n",
    "    max_val = max(actuals.max(), predictions.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], \n",
    "             color='red', linestyle='--', label='Perfect Prediction')\n",
    "    \n",
    "    plt.title(f'Predicted vs. Actual Returns - {model_name}', fontsize=14)\n",
    "    plt.xlabel('Actual Returns', fontsize=12)\n",
    "    plt.ylabel('Predicted Returns', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.5)\n",
    "    \n",
    "    # Residual plot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.scatter(predictions, filtered_df['Residual'], alpha=0.7)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.title('Residual Plot', fontsize=14)\n",
    "    plt.xlabel('Predicted Returns', fontsize=12)\n",
    "    plt.ylabel('Residual', fontsize=12)\n",
    "    plt.grid(alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "# Function to get random test tickers\n",
    "def get_random_test_tickers(n_tickers):\n",
    "    \"\"\"\n",
    "    Get random US-listed tickers that aren't in our training set.\n",
    "    \n",
    "    Args:\n",
    "        n_tickers (int): Number of test tickers to return\n",
    "        \n",
    "    Returns:\n",
    "        list: List of ticker symbols\n",
    "    \"\"\"\n",
    "    training_tickers = set(stockFetcher.symbols)\n",
    "    \n",
    "    # Get US exchange tickers using pandas_datareader\n",
    "    try:\n",
    "        # Get ADR tickers\n",
    "        adr_df = pd.read_csv(testFolder / 'tickers.csv')\n",
    "        tickers = adr_df['Ticker'].tolist()\n",
    "        \n",
    "        # Clean tickers (remove warrants, preferred shares, etc.)\n",
    "        clean_tickers = [\n",
    "            ticker for ticker in tickers \n",
    "            if ticker not in training_tickers\n",
    "        ]\n",
    "        \n",
    "        # Randomly select tickers\n",
    "        if len(clean_tickers) < n_tickers:\n",
    "            print(f\"Warning: Only {len(clean_tickers)} tickers available\")\n",
    "            return clean_tickers\n",
    "            \n",
    "        return np.random.choice(clean_tickers, size=n_tickers, replace=False).tolist()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching tickers: {e}\")\n",
    "        # Fallback to a list of common US tickers not in training set\n",
    "        fallback_tickers = [\n",
    "            'KO', 'PEP', 'JNJ', 'PG', 'WMT', 'HD', 'MCD', 'NKE', \n",
    "            'DIS', 'SBUX', 'COST', 'TGT', 'LOW', 'MO', 'CVS'\n",
    "        ]\n",
    "        fallback_tickers = [t for t in fallback_tickers if t not in training_tickers]\n",
    "        return np.random.choice(fallback_tickers, size=min(n_tickers, len(fallback_tickers)), replace=False).tolist()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Evaluate model (replace learn with your actual learner)\n",
    "    mae, rmse, r2 = evaluate_model(\n",
    "        learn=learn,  # Your fastai learner\n",
    "        test_tickers = get_random_test_tickers(n_tickers=testSize),\n",
    "        model_name=modelName,\n",
    "        model_folder=modelFolder,\n",
    "        cont_names=contNames,\n",
    "        cat_names=catNames\n",
    "    )\n",
    "    \n",
    "    if mae is not None and rmse is not None and r2 is not None:\n",
    "        print(f\"Evaluation Results:\")\n",
    "        print(f\"MAE: {mae:.3f}\")\n",
    "        print(f\"RMSE: {rmse:.3f}\")\n",
    "        print(f\"R2: {r2:.3f}\")\n",
    "    else:\n",
    "        print(\"Evaluation failed. Metrics are None.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(modelFolder / f'{modelName}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests (recommended to use the app instead, but feel free to use the tests below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To get prediction on a new dataframe, you can use the test_dl method of the DataLoaders. That dataframe does not need to have the dependent variable in its column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>ROIC</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232.119995</td>\n",
       "      <td>232.289993</td>\n",
       "      <td>228.479996</td>\n",
       "      <td>229.979996</td>\n",
       "      <td>68247100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.880474</td>\n",
       "      <td>3.458416e+12</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>Consumer Electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open        High         Low       Close    Volume  Dividends  \\\n",
       "0  232.119995  232.289993  228.479996  229.979996  68247100        0.0   \n",
       "\n",
       "   Stock Splits    EV/EBIT    Market Cap      ROIC              Industry  \n",
       "0           0.0  59.880474  3.458416e+12  0.013193  Consumer Electronics  "
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionTarget = 'AAPL'\n",
    "\n",
    "test_df = stockFetcher.getTickerData(predictionTarget)\n",
    "\n",
    "# Ensure test_df is a DataFrame\n",
    "if isinstance(test_df, dict):\n",
    "\ttest_df = pd.DataFrame([test_df])\n",
    "\n",
    "dl = learn.dls.test_dl(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for AAPL:\n",
      "-69.96%\n"
     ]
    }
   ],
   "source": [
    "prediction = learn.get_preds(dl=dl)\n",
    "print(f\"Prediction for {predictionTarget}:\")\n",
    "print(f\"{prediction[0][0][0].item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "Since machine learning models can’t magically understand categories it was never trained on, the data should reflect this. If there are different missing values in your test data you should address this before training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
