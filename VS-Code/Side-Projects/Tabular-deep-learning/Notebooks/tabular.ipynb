{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries on first run\n",
    "#! pip install -q ipynb fastai pathlib pandas import_ipynb numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'stockScreenerV3.0'\n",
    "trainingDataName = 'stockData.csv'\n",
    "trainingFolder = Path.cwd().parent / 'TrainingData'\n",
    "modelFolder = Path.cwd().parent.parent / 'TrainedModels'\n",
    "testFolder = Path.cwd().parent / 'TestData'\n",
    "\n",
    "# Training parameters\n",
    "yNames = ['Future Year Change']\n",
    "catNames = ['Industry']\n",
    "contNames = [\n",
    "    'Open',\n",
    "    'High', \n",
    "    'Low', \n",
    "    'Close', \n",
    "    'Volume', \n",
    "    'Dividends', \n",
    "    'Stock Splits', \n",
    "    'EV/EBIT', \n",
    "    'ROIC'\n",
    "]\n",
    "epochs = 2\n",
    "\n",
    "# Test parameters\n",
    "testSize = 100 # Number of stocks to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can have a look at how the data is structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Future Year Change</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Capital Gains</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>ROIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-20 00:00:00-04:00</td>\n",
       "      <td>16.25</td>\n",
       "      <td>16.990</td>\n",
       "      <td>14.00</td>\n",
       "      <td>16.26</td>\n",
       "      <td>37563700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.194342</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.190711</td>\n",
       "      <td>0.360613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-23 00:00:00-04:00</td>\n",
       "      <td>16.10</td>\n",
       "      <td>16.399</td>\n",
       "      <td>15.12</td>\n",
       "      <td>15.26</td>\n",
       "      <td>5753800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.145478</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.963060</td>\n",
       "      <td>0.402433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-24 00:00:00-04:00</td>\n",
       "      <td>15.40</td>\n",
       "      <td>15.860</td>\n",
       "      <td>14.77</td>\n",
       "      <td>15.24</td>\n",
       "      <td>3748300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.179134</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.958507</td>\n",
       "      <td>0.403368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-25 00:00:00-04:00</td>\n",
       "      <td>15.10</td>\n",
       "      <td>15.430</td>\n",
       "      <td>13.62</td>\n",
       "      <td>13.73</td>\n",
       "      <td>4408100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.071377</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.614754</td>\n",
       "      <td>0.489238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-26 00:00:00-04:00</td>\n",
       "      <td>13.82</td>\n",
       "      <td>14.160</td>\n",
       "      <td>13.81</td>\n",
       "      <td>14.02</td>\n",
       "      <td>1850000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.099857</td>\n",
       "      <td>SE</td>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.680773</td>\n",
       "      <td>0.470022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date   Open    High    Low  Close      Volume  \\\n",
       "0  2017-10-20 00:00:00-04:00  16.25  16.990  14.00  16.26  37563700.0   \n",
       "1  2017-10-23 00:00:00-04:00  16.10  16.399  15.12  15.26   5753800.0   \n",
       "2  2017-10-24 00:00:00-04:00  15.40  15.860  14.77  15.24   3748300.0   \n",
       "3  2017-10-25 00:00:00-04:00  15.10  15.430  13.62  13.73   4408100.0   \n",
       "4  2017-10-26 00:00:00-04:00  13.82  14.160  13.81  14.02   1850000.0   \n",
       "\n",
       "   Dividends  Stock Splits  Future Year Change Ticker         Industry  \\\n",
       "0        0.0           0.0           -0.194342     SE  Internet Retail   \n",
       "1        0.0           0.0           -0.145478     SE  Internet Retail   \n",
       "2        0.0           0.0           -0.179134     SE  Internet Retail   \n",
       "3        0.0           0.0           -0.071377     SE  Internet Retail   \n",
       "4        0.0           0.0           -0.099857     SE  Internet Retail   \n",
       "\n",
       "   Adj Close  Capital Gains   EV/EBIT      ROIC  \n",
       "0        NaN            NaN  2.190711  0.360613  \n",
       "1        NaN            NaN  1.963060  0.402433  \n",
       "2        NaN            NaN  1.958507  0.403368  \n",
       "3        NaN            NaN  1.614754  0.489238  \n",
       "4        NaN            NaN  1.680773  0.470022  "
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPath = Path()\n",
    "df = pd.read_csv(trainingFolder/trainingDataName)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns are continuous (like age) and we will treat them as float numbers we can feed our model directly. Others are categorical (like workclass or education) and we will convert them to a unique index that we will feed to embedding layers. We can specify our categorical and continuous column names, as well as the name of the dependent variable in TabularDataLoaders factory methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dls = TabularDataLoaders.from_csv(trainingFolder/trainingDataName, path=dataPath, \n",
    "    y_names=yNames,\n",
    "    cat_names=catNames,\n",
    "    cont_names=contNames,\n",
    "    procs = [Categorify, FillMissing, Normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part is the list of pre-processors we apply to our data:\n",
    "\n",
    "* Categorify is going to take every categorical variable and make a map from integer to unique categories, then replace the values by the corresponding index.\n",
    "* FillMissing will fill the missing values in the continuous variables by the median of existing values (you can choose a specific value if you prefer)\n",
    "* Normalize will normalize the continuous variables (subtract the mean and divide by the std)\n",
    "\n",
    "To further expose what’s going on below the surface, let’s rewrite this utilizing fastai’s TabularPandas class. We will need to make one adjustment, which is defining how we want to split our data. By default the factory method above used a random 80/20 split, so we will do the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = EndSplitter (valid_pct=0.2, valid_last=True)(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "to = TabularPandas(df, procs=[Categorify, FillMissing, Normalize],\n",
    "    y_names=yNames,\n",
    "    cat_names = catNames,\n",
    "    cont_names = contNames,\n",
    "    splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we build our TabularPandas object, our data is completely preprocessed as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>EV/EBIT_na</th>\n",
       "      <th>ROIC_na</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>ROIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.161926</td>\n",
       "      <td>-0.157894</td>\n",
       "      <td>-0.183005</td>\n",
       "      <td>-0.162741</td>\n",
       "      <td>5.635154</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.19608</td>\n",
       "      <td>-0.085114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Industry  EV/EBIT_na  ROIC_na      Open      High       Low     Close  \\\n",
       "0        23           1        1 -0.161926 -0.157894 -0.183005 -0.162741   \n",
       "\n",
       "     Volume  Dividends  Stock Splits  EV/EBIT      ROIC  \n",
       "0  5.635154  -0.050866     -0.013349 -0.19608 -0.085114  "
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.xs.iloc[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build our DataLoaders again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The show_batch method works like for every other application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>EV/EBIT_na</th>\n",
       "      <th>ROIC_na</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>ROIC</th>\n",
       "      <th>Future Year Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aluminum</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.994418</td>\n",
       "      <td>2.010076</td>\n",
       "      <td>1.991290</td>\n",
       "      <td>2.010073</td>\n",
       "      <td>5.393299e+04</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>1.303352</td>\n",
       "      <td>0.606130</td>\n",
       "      <td>-0.028148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialty Business Services</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.199209</td>\n",
       "      <td>5.247439</td>\n",
       "      <td>5.189229</td>\n",
       "      <td>5.195881</td>\n",
       "      <td>9.159991e+04</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>11.792067</td>\n",
       "      <td>0.066994</td>\n",
       "      <td>0.149287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software - Infrastructure</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>285.350009</td>\n",
       "      <td>287.149990</td>\n",
       "      <td>280.560002</td>\n",
       "      <td>286.799994</td>\n",
       "      <td>4.760000e+05</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>64.220670</td>\n",
       "      <td>0.012301</td>\n",
       "      <td>-0.287273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Banks - Diversified</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29.064284</td>\n",
       "      <td>29.067932</td>\n",
       "      <td>28.918360</td>\n",
       "      <td>29.027804</td>\n",
       "      <td>2.132000e+05</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>-31.604159</td>\n",
       "      <td>-0.024996</td>\n",
       "      <td>0.139638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Internet Retail</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>160.236684</td>\n",
       "      <td>160.265663</td>\n",
       "      <td>156.026033</td>\n",
       "      <td>156.450954</td>\n",
       "      <td>1.061520e+07</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>1.144411</td>\n",
       "      <td>0.690311</td>\n",
       "      <td>0.023272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Solar</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>55.880001</td>\n",
       "      <td>56.750000</td>\n",
       "      <td>54.490001</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>1.175100e+06</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>9.336225</td>\n",
       "      <td>0.084617</td>\n",
       "      <td>3.513005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Oil &amp; Gas Integrated</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>28.890104</td>\n",
       "      <td>29.020035</td>\n",
       "      <td>28.714317</td>\n",
       "      <td>28.737245</td>\n",
       "      <td>6.105900e+06</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>3.754714</td>\n",
       "      <td>0.210403</td>\n",
       "      <td>-0.395126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Banks - Diversified</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15.756809</td>\n",
       "      <td>15.783613</td>\n",
       "      <td>15.500938</td>\n",
       "      <td>15.547238</td>\n",
       "      <td>3.736000e+05</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>2.868898</td>\n",
       "      <td>0.275367</td>\n",
       "      <td>0.298291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beverages - Wineries &amp; Distilleries</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10.465933</td>\n",
       "      <td>10.627777</td>\n",
       "      <td>10.465932</td>\n",
       "      <td>10.519883</td>\n",
       "      <td>3.859998e+04</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>8.854311</td>\n",
       "      <td>0.089222</td>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>17.433594</td>\n",
       "      <td>17.766074</td>\n",
       "      <td>17.401421</td>\n",
       "      <td>17.648096</td>\n",
       "      <td>2.928001e+05</td>\n",
       "      <td>-2.991955e-11</td>\n",
       "      <td>1.158889e-12</td>\n",
       "      <td>4.719044</td>\n",
       "      <td>0.095212</td>\n",
       "      <td>0.104912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a model using the tabular_learner method. When we define our model, fastai will try to infer the loss function based on our y_names earlier.\n",
    "\n",
    "Note: Sometimes with tabular data, your y’s may be encoded (such as 0 and 1). In such a case you should explicitly pass y_block = CategoryBlock in your constructor so fastai won’t presume you are doing regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=[rmse, mae])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can train that model with the fit_one_cycle method (the fine_tune method won’t be useful here since we don’t have a pretrained model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stockScreenerV3.0 for 2 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.915538</td>\n",
       "      <td>635302.250000</td>\n",
       "      <td>797.058716</td>\n",
       "      <td>11.074199</td>\n",
       "      <td>01:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.975554</td>\n",
       "      <td>5080544.000000</td>\n",
       "      <td>2254.006348</td>\n",
       "      <td>28.492224</td>\n",
       "      <td>01:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Training {modelName} for {epochs} epochs\")\n",
    "learn.fit_one_cycle(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then have a look at some training predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>EV/EBIT_na</th>\n",
       "      <th>ROIC_na</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>ROIC</th>\n",
       "      <th>Future Year Change</th>\n",
       "      <th>Future Year Change_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.240541</td>\n",
       "      <td>-0.242095</td>\n",
       "      <td>-0.240705</td>\n",
       "      <td>-0.240842</td>\n",
       "      <td>-0.325975</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.309470</td>\n",
       "      <td>-0.087906</td>\n",
       "      <td>-0.364208</td>\n",
       "      <td>0.044148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.211911</td>\n",
       "      <td>-0.213705</td>\n",
       "      <td>-0.212044</td>\n",
       "      <td>-0.212523</td>\n",
       "      <td>-0.482072</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-5.320011</td>\n",
       "      <td>-0.088565</td>\n",
       "      <td>-0.574354</td>\n",
       "      <td>0.016379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.266936</td>\n",
       "      <td>-0.268429</td>\n",
       "      <td>-0.267422</td>\n",
       "      <td>-0.268192</td>\n",
       "      <td>1.352797</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.036688</td>\n",
       "      <td>-0.087141</td>\n",
       "      <td>0.856337</td>\n",
       "      <td>-0.001043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.242728</td>\n",
       "      <td>-0.244020</td>\n",
       "      <td>-0.244270</td>\n",
       "      <td>-0.242862</td>\n",
       "      <td>0.540030</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.349457</td>\n",
       "      <td>-0.096151</td>\n",
       "      <td>1.041816</td>\n",
       "      <td>1.161095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.242046</td>\n",
       "      <td>-0.243642</td>\n",
       "      <td>-0.241959</td>\n",
       "      <td>-0.242495</td>\n",
       "      <td>0.327020</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.047646</td>\n",
       "      <td>-0.087083</td>\n",
       "      <td>0.129276</td>\n",
       "      <td>0.479999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.173874</td>\n",
       "      <td>-0.174360</td>\n",
       "      <td>-0.173094</td>\n",
       "      <td>-0.174174</td>\n",
       "      <td>1.436521</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>1.018593</td>\n",
       "      <td>-0.088222</td>\n",
       "      <td>-0.533724</td>\n",
       "      <td>0.033117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.253511</td>\n",
       "      <td>-0.255738</td>\n",
       "      <td>-0.254084</td>\n",
       "      <td>-0.254760</td>\n",
       "      <td>-0.197302</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.350216</td>\n",
       "      <td>-0.087943</td>\n",
       "      <td>-0.108614</td>\n",
       "      <td>0.061872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.633380</td>\n",
       "      <td>0.637155</td>\n",
       "      <td>0.620665</td>\n",
       "      <td>0.646249</td>\n",
       "      <td>-0.112532</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>6.359062</td>\n",
       "      <td>-0.088440</td>\n",
       "      <td>-0.074592</td>\n",
       "      <td>-0.433975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517324</td>\n",
       "      <td>0.558773</td>\n",
       "      <td>0.509650</td>\n",
       "      <td>0.552436</td>\n",
       "      <td>-0.252170</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.229739</td>\n",
       "      <td>-0.083551</td>\n",
       "      <td>-0.193242</td>\n",
       "      <td>0.782532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.029161</td>\n",
       "      <td>-0.031924</td>\n",
       "      <td>-0.029674</td>\n",
       "      <td>-0.029326</td>\n",
       "      <td>0.136320</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.189360</td>\n",
       "      <td>-0.087763</td>\n",
       "      <td>0.171889</td>\n",
       "      <td>-0.010915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.342626</td>\n",
       "      <td>0.338940</td>\n",
       "      <td>0.344488</td>\n",
       "      <td>0.339061</td>\n",
       "      <td>-0.303277</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.186266</td>\n",
       "      <td>-0.087758</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.124679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.322769</td>\n",
       "      <td>-0.320921</td>\n",
       "      <td>-0.319849</td>\n",
       "      <td>-0.320364</td>\n",
       "      <td>-0.479642</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.241531</td>\n",
       "      <td>-0.082595</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.312496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.090273</td>\n",
       "      <td>-0.092318</td>\n",
       "      <td>-0.087986</td>\n",
       "      <td>-0.091192</td>\n",
       "      <td>-0.503424</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.027495</td>\n",
       "      <td>-0.087186</td>\n",
       "      <td>0.108282</td>\n",
       "      <td>0.043421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.254639</td>\n",
       "      <td>-0.256693</td>\n",
       "      <td>-0.255167</td>\n",
       "      <td>-0.256029</td>\n",
       "      <td>0.172811</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>0.536316</td>\n",
       "      <td>-0.088065</td>\n",
       "      <td>-0.492203</td>\n",
       "      <td>0.037203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.184835</td>\n",
       "      <td>-0.185934</td>\n",
       "      <td>-0.184258</td>\n",
       "      <td>-0.184116</td>\n",
       "      <td>-0.202746</td>\n",
       "      <td>-0.050866</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.026620</td>\n",
       "      <td>-0.087190</td>\n",
       "      <td>-0.170915</td>\n",
       "      <td>-0.002412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(max_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stockFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$EOG: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$GSK: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$IBKR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for EOG: No historical data available for EOG around 2024-01-21.\n",
      "Skipping EOG due to missing data\n",
      "Error fetching data for GSK: No historical data available for GSK around 2024-01-21.\n",
      "Skipping GSK due to missing data\n",
      "Error fetching data for IBKR: No historical data available for IBKR around 2024-01-21.\n",
      "Skipping IBKR due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DDOG: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$AMTD: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$DEO: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$ING: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DDOG: No historical data available for DDOG around 2024-01-21.\n",
      "Skipping DDOG due to missing data\n",
      "Error fetching data for AMTD: No historical data available for AMTD around 2024-01-21.\n",
      "Skipping AMTD due to missing data\n",
      "Error fetching data for DEO: No historical data available for DEO around 2024-01-21.\n",
      "Skipping DEO due to missing data\n",
      "Error fetching data for ING: No historical data available for ING around 2024-01-21.\n",
      "Skipping ING due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WMB: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for WMB: No historical data available for WMB around 2024-01-21.\n",
      "Skipping WMB due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HAL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$PLUG: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TECK: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HAL: No historical data available for HAL around 2024-01-21.\n",
      "Skipping HAL due to missing data\n",
      "Error fetching data for PLUG: No historical data available for PLUG around 2024-01-21.\n",
      "Skipping PLUG due to missing data\n",
      "Error fetching data for TECK: No historical data available for TECK around 2024-01-21.\n",
      "Skipping TECK due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NESTLE: possibly delisted; no timezone found\n",
      "$RDFN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$NTTYY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NESTLE: No historical data available for NESTLE around 2024-01-21.\n",
      "Skipping NESTLE due to missing data\n",
      "Error fetching data for RDFN: No historical data available for RDFN around 2024-01-21.\n",
      "Skipping RDFN due to missing data\n",
      "Error fetching data for NTTYY: No historical data available for NTTYY around 2024-01-21.\n",
      "Skipping NTTYY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DSY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TAL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$Z: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DSY: No historical data available for DSY around 2024-01-21.\n",
      "Skipping DSY due to missing data\n",
      "Error fetching data for TAL: No historical data available for TAL around 2024-01-21.\n",
      "Skipping TAL due to missing data\n",
      "Error fetching data for Z: No historical data available for Z around 2024-01-21.\n",
      "Skipping Z due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$HIG: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AM: No historical data available for AM around 2024-01-21.\n",
      "Skipping AM due to missing data\n",
      "Error fetching data for HIG: No historical data available for HIG around 2024-01-21.\n",
      "Skipping HIG due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FRC: possibly delisted; no timezone found\n",
      "$ENPH: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$AFRM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$AGI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for FRC: No historical data available for FRC around 2024-01-21.\n",
      "Skipping FRC due to missing data\n",
      "Error fetching data for ENPH: No historical data available for ENPH around 2024-01-21.\n",
      "Skipping ENPH due to missing data\n",
      "Error fetching data for AFRM: No historical data available for AFRM around 2024-01-21.\n",
      "Skipping AFRM due to missing data\n",
      "Error fetching data for AGI: No historical data available for AGI around 2024-01-21.\n",
      "Skipping AGI due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$IMBBY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$HSBC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for IMBBY: No historical data available for IMBBY around 2024-01-21.\n",
      "Skipping IMBBY due to missing data\n",
      "Error fetching data for HSBC: No historical data available for HSBC around 2024-01-21.\n",
      "Skipping HSBC due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NTR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$DASH: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$PM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$SPGI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$WBK: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NTR: No historical data available for NTR around 2024-01-21.\n",
      "Skipping NTR due to missing data\n",
      "Error fetching data for DASH: No historical data available for DASH around 2024-01-21.\n",
      "Skipping DASH due to missing data\n",
      "Error fetching data for PM: No historical data available for PM around 2024-01-21.\n",
      "Skipping PM due to missing data\n",
      "Error fetching data for SPGI: No historical data available for SPGI around 2024-01-21.\n",
      "Skipping SPGI due to missing data\n",
      "Error fetching data for WBK: No historical data available for WBK around 2024-01-21.\n",
      "Skipping WBK due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VIPS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for VIPS: No historical data available for VIPS around 2024-01-21.\n",
      "Skipping VIPS due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AA: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$CSGN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$BABA: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$EL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AA: No historical data available for AA around 2024-01-21.\n",
      "Skipping AA due to missing data\n",
      "Error fetching data for CSGN: No historical data available for CSGN around 2024-01-21.\n",
      "Skipping CSGN due to missing data\n",
      "Error fetching data for BABA: No historical data available for BABA around 2024-01-21.\n",
      "Skipping BABA due to missing data\n",
      "Error fetching data for EL: No historical data available for EL around 2024-01-21.\n",
      "Skipping EL due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ADSK: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$SNY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ADSK: No historical data available for ADSK around 2024-01-21.\n",
      "Skipping ADSK due to missing data\n",
      "Error fetching data for SNY: No historical data available for SNY around 2024-01-21.\n",
      "Skipping SNY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AU: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$VOD: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AU: No historical data available for AU around 2024-01-21.\n",
      "Skipping AU due to missing data\n",
      "Error fetching data for VOD: No historical data available for VOD around 2024-01-21.\n",
      "Skipping VOD due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BLDP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$BAM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$AMT: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$SAP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$SONY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BLDP: No historical data available for BLDP around 2024-01-21.\n",
      "Skipping BLDP due to missing data\n",
      "Error fetching data for BAM: No historical data available for BAM around 2024-01-21.\n",
      "Skipping BAM due to missing data\n",
      "Error fetching data for AMT: No historical data available for AMT around 2024-01-21.\n",
      "Skipping AMT due to missing data\n",
      "Error fetching data for SAP: No historical data available for SAP around 2024-01-21.\n",
      "Skipping SAP due to missing data\n",
      "Error fetching data for SONY: No historical data available for SONY around 2024-01-21.\n",
      "Skipping SONY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FSLY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$LMND: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$BKR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for FSLY: No historical data available for FSLY around 2024-01-21.\n",
      "Skipping FSLY due to missing data\n",
      "Error fetching data for LMND: No historical data available for LMND around 2024-01-21.\n",
      "Skipping LMND due to missing data\n",
      "Error fetching data for BKR: No historical data available for BKR around 2024-01-21.\n",
      "Skipping BKR due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VWAGY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$SAN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for VWAGY: No historical data available for VWAGY around 2024-01-21.\n",
      "Skipping VWAGY due to missing data\n",
      "Error fetching data for SAN: No historical data available for SAN around 2024-01-21.\n",
      "Skipping SAN due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$UBS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$CX: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$EDU: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for UBS: No historical data available for UBS around 2024-01-21.\n",
      "Skipping UBS due to missing data\n",
      "Error fetching data for CX: No historical data available for CX around 2024-01-21.\n",
      "Skipping CX due to missing data\n",
      "Error fetching data for EDU: No historical data available for EDU around 2024-01-21.\n",
      "Skipping EDU due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GFI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$RLI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$STM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GFI: No historical data available for GFI around 2024-01-21.\n",
      "Skipping GFI due to missing data\n",
      "Error fetching data for RLI: No historical data available for RLI around 2024-01-21.\n",
      "Skipping RLI due to missing data\n",
      "Error fetching data for STM: No historical data available for STM around 2024-01-21.\n",
      "Skipping STM due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HBAN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$JKS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HBAN: No historical data available for HBAN around 2024-01-21.\n",
      "Skipping HBAN due to missing data\n",
      "Error fetching data for JKS: No historical data available for JKS around 2024-01-21.\n",
      "Skipping JKS due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DLR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TSN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for DLR: No historical data available for DLR around 2024-01-21.\n",
      "Skipping DLR due to missing data\n",
      "Error fetching data for TSN: No historical data available for TSN around 2024-01-21.\n",
      "Skipping TSN due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NVS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$SIEGY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NVS: No historical data available for NVS around 2024-01-21.\n",
      "Skipping NVS due to missing data\n",
      "Error fetching data for SIEGY: No historical data available for SIEGY around 2024-01-21.\n",
      "Skipping SIEGY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$OKE: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$RELX: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$CHKP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for OKE: No historical data available for OKE around 2024-01-21.\n",
      "Skipping OKE due to missing data\n",
      "Error fetching data for RELX: No historical data available for RELX around 2024-01-21.\n",
      "Skipping RELX due to missing data\n",
      "Error fetching data for CHKP: No historical data available for CHKP around 2024-01-21.\n",
      "Skipping CHKP due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BP: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$ALLY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for BP: No historical data available for BP around 2024-01-21.\n",
      "Skipping BP due to missing data\n",
      "Error fetching data for ALLY: No historical data available for ALLY around 2024-01-21.\n",
      "Skipping ALLY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ET: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$TWLO: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$COF: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ET: No historical data available for ET around 2024-01-21.\n",
      "Skipping ET due to missing data\n",
      "Error fetching data for TWLO: No historical data available for TWLO around 2024-01-21.\n",
      "Skipping TWLO due to missing data\n",
      "Error fetching data for COF: No historical data available for COF around 2024-01-21.\n",
      "Skipping COF due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MSCI: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$U: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$GDS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for MSCI: No historical data available for MSCI around 2024-01-21.\n",
      "Skipping MSCI due to missing data\n",
      "Error fetching data for U: No historical data available for U around 2024-01-21.\n",
      "Skipping U due to missing data\n",
      "Error fetching data for GDS: No historical data available for GDS around 2024-01-21.\n",
      "Skipping GDS due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ABBV: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$LVMUY: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ABBV: No historical data available for ABBV around 2024-01-21.\n",
      "Skipping ABBV due to missing data\n",
      "Error fetching data for LVMUY: No historical data available for LVMUY around 2024-01-21.\n",
      "Skipping LVMUY due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FERR: possibly delisted; no timezone found\n",
      "$ALB: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for FERR: No historical data available for FERR around 2024-01-21.\n",
      "Skipping FERR due to missing data\n",
      "Error fetching data for ALB: No historical data available for ALB around 2024-01-21.\n",
      "Skipping ALB due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NEM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$CYBR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$BBVA: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NEM: No historical data available for NEM around 2024-01-21.\n",
      "Skipping NEM due to missing data\n",
      "Error fetching data for CYBR: No historical data available for CYBR around 2024-01-21.\n",
      "Skipping CYBR due to missing data\n",
      "Error fetching data for BBVA: No historical data available for BBVA around 2024-01-21.\n",
      "Skipping BBVA due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ANZBY: possibly delisted; no timezone found\n",
      "$PAAS: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for ANZBY: No historical data available for ANZBY around 2024-01-21.\n",
      "Skipping ANZBY due to missing data\n",
      "Error fetching data for PAAS: No historical data available for PAAS around 2024-01-21.\n",
      "Skipping PAAS due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NESN: possibly delisted; no timezone found\n",
      "$TFC: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for NESN: No historical data available for NESN around 2024-01-21.\n",
      "Skipping NESN due to missing data\n",
      "Error fetching data for TFC: No historical data available for TFC around 2024-01-21.\n",
      "Skipping TFC due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AZO: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for AZO: No historical data available for AZO around 2024-01-21.\n",
      "Skipping AZO due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SANB: possibly delisted; no timezone found\n",
      "$NET: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$WIX: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for SANB: No historical data available for SANB around 2024-01-21.\n",
      "Skipping SANB due to missing data\n",
      "Error fetching data for NET: No historical data available for NET around 2024-01-21.\n",
      "Skipping NET due to missing data\n",
      "Error fetching data for WIX: No historical data available for WIX around 2024-01-21.\n",
      "Skipping WIX due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CBAUF: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$MAXN: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$ACGL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CBAUF: No historical data available for CBAUF around 2024-01-21.\n",
      "Skipping CBAUF due to missing data\n",
      "Error fetching data for MAXN: No historical data available for MAXN around 2024-01-21.\n",
      "Skipping MAXN due to missing data\n",
      "Error fetching data for ACGL: No historical data available for ACGL around 2024-01-21.\n",
      "Skipping ACGL due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FVRR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for FVRR: No historical data available for FVRR around 2024-01-21.\n",
      "Skipping FVRR due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for CS: No historical data available for CS around 2024-01-21.\n",
      "Skipping CS due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TOT: possibly delisted; no timezone found\n",
      "$MKL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$CME: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for TOT: No historical data available for TOT around 2024-01-21.\n",
      "Skipping TOT due to missing data\n",
      "Error fetching data for MKL: No historical data available for MKL around 2024-01-21.\n",
      "Skipping MKL due to missing data\n",
      "Error fetching data for CME: No historical data available for CME around 2024-01-21.\n",
      "Skipping CME due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$IRM: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$VLO: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for IRM: No historical data available for IRM around 2024-01-21.\n",
      "Skipping IRM due to missing data\n",
      "Error fetching data for VLO: No historical data available for VLO around 2024-01-21.\n",
      "Skipping VLO due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GFL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n",
      "$PGR: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for GFL: No historical data available for GFL around 2024-01-21.\n",
      "Skipping GFL due to missing data\n",
      "Error fetching data for PGR: No historical data available for PGR around 2024-01-21.\n",
      "Skipping PGR due to missing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HRL: possibly delisted; no price data found  (1d 2024-01-20 -> 2024-01-22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for HRL: No historical data available for HRL around 2024-01-21.\n",
      "Skipping HRL due to missing data\n",
      "No valid test data collected\n",
      "Evaluation failed. Metrics are None.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(learn, test_tickers, model_name, model_folder, cont_names, cat_names):\n",
    "    \"\"\"\n",
    "    Evaluate a fastai model on a list of test tickers and log the results.\n",
    "    \n",
    "    Args:\n",
    "        learn: fastai Learner object\n",
    "        test_tickers (list): List of ticker symbols to test on\n",
    "        model_name (str): Name of the model for logging\n",
    "        model_folder (Path): Path to save evaluation results\n",
    "        cont_names (list): List of continuous feature names\n",
    "        cat_names (list): List of categorical feature names\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "    test_data_list = []\n",
    "    \n",
    "    # Collect test data for all tickers\n",
    "    for ticker in test_tickers:\n",
    "        try:\n",
    "            # Get test data\n",
    "            test_data = stockFetcher.getTickerDataFrom1YrAgo(ticker)\n",
    "            if test_data.empty:\n",
    "                print(f\"Skipping {ticker} due to missing data\")\n",
    "                continue\n",
    "            \n",
    "            test_data_list.append(test_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not test_data_list:\n",
    "        print(\"No valid test data collected\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Combine all test data\n",
    "    combined_test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "    \n",
    "    # Create fastai test dataloader\n",
    "    test_dl = learn.dls.test_dl(combined_test_data)\n",
    "    \n",
    "    # Get predictions\n",
    "    preds, targs = learn.get_preds(dl=test_dl)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    predictions = preds.numpy()\n",
    "    actuals = targs.numpy()\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'Predicted': predictions.flatten(),\n",
    "        'Actual': actuals.flatten()\n",
    "    })\n",
    "\n",
    "    # Calculate residuals\n",
    "    results_df['Residual'] = results_df['Actual'] - results_df['Predicted']\n",
    "\n",
    "    # Define outlier threshold (2 standard deviations)\n",
    "    outlier_threshold = 2 * results_df['Residual'].std()\n",
    "\n",
    "    # Filter outliers\n",
    "    filtered_df = results_df[abs(results_df['Residual']) <= outlier_threshold]\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(filtered_df['Residual']))\n",
    "    rmse = np.sqrt(np.mean(filtered_df['Residual']**2))\n",
    "    r2 = 1 - (np.sum(filtered_df['Residual']**2) / \n",
    "              np.sum((filtered_df['Actual'] - filtered_df['Actual'].mean())**2))\n",
    "\n",
    "    # Log results\n",
    "    log_evaluation(model_name, mae, rmse, r2, model_folder)\n",
    "    \n",
    "    # Create visualizations\n",
    "    plot_results(filtered_df, model_name, model_folder)\n",
    "    \n",
    "    return mae, rmse, r2\n",
    "\n",
    "def log_evaluation(model_name, mae, rmse, r2, model_folder):\n",
    "    \"\"\"Log evaluation metrics to CSV file\"\"\"\n",
    "    log_file = model_folder / \"modelEvaluations.csv\"\n",
    "    \n",
    "    new_entry_df = pd.DataFrame([{\n",
    "        \"Model Name\": modelName,\n",
    "        \"Timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "        \"MAE\": f'{mae:.3f}',\n",
    "        \"RMSE\": f'{rmse:.3f}',\n",
    "        \"R2\": f'{r2:.3f}',\n",
    "        \"Epochs\": epochs,\n",
    "        \"Test Amount\": len(get_random_test_tickers(n_tickers=testSize)),\n",
    "        \"Cat Names\": catNames,\n",
    "        \"Cont Names\": contNames,\n",
    "    }])\n",
    "    \n",
    "    try:\n",
    "        log_df = pd.read_csv(log_file)\n",
    "        log_df = pd.concat([log_df, new_entry_df], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        log_df = new_entry_df\n",
    "        \n",
    "    log_df.to_csv(log_file, index=False)\n",
    "    print(f\"Logged evaluation results to {log_file}\")\n",
    "\n",
    "def plot_results(filtered_df, model_name, model_folder):\n",
    "    \"\"\"Create and save visualization plots\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    actuals = filtered_df['Actual']\n",
    "    predictions = filtered_df['Predicted']\n",
    "    plt.scatter(actuals, predictions, alpha=0.7, label='Predictions')\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(actuals.min(), predictions.min())\n",
    "    max_val = max(actuals.max(), predictions.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], \n",
    "             color='red', linestyle='--', label='Perfect Prediction')\n",
    "    \n",
    "    plt.title(f'Predicted vs. Actual Returns - {model_name}', fontsize=14)\n",
    "    plt.xlabel('Actual Returns', fontsize=12)\n",
    "    plt.ylabel('Predicted Returns', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.5)\n",
    "    \n",
    "    # Residual plot\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.scatter(predictions, filtered_df['Residual'], alpha=0.7)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.title('Residual Plot', fontsize=14)\n",
    "    plt.xlabel('Predicted Returns', fontsize=12)\n",
    "    plt.ylabel('Residual', fontsize=12)\n",
    "    plt.grid(alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "# Function to get random test tickers\n",
    "def get_random_test_tickers(n_tickers):\n",
    "    \"\"\"\n",
    "    Get random US-listed tickers that aren't in our training set.\n",
    "    \n",
    "    Args:\n",
    "        n_tickers (int): Number of test tickers to return\n",
    "        \n",
    "    Returns:\n",
    "        list: List of ticker symbols\n",
    "    \"\"\"\n",
    "    training_tickers = set(stockFetcher.symbols)\n",
    "    \n",
    "    # Get US exchange tickers using pandas_datareader\n",
    "    try:\n",
    "        # Get ADR tickers\n",
    "        adr_df = pd.read_csv(testFolder / 'tickers.csv')\n",
    "        tickers = adr_df['Ticker'].tolist()\n",
    "        \n",
    "        # Clean tickers (remove warrants, preferred shares, etc.)\n",
    "        clean_tickers = [\n",
    "            ticker for ticker in tickers \n",
    "            if ticker not in training_tickers\n",
    "        ]\n",
    "        \n",
    "        # Randomly select tickers\n",
    "        if len(clean_tickers) < n_tickers:\n",
    "            print(f\"Warning: Only {len(clean_tickers)} tickers available\")\n",
    "            return clean_tickers\n",
    "            \n",
    "        return np.random.choice(clean_tickers, size=n_tickers, replace=False).tolist()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching tickers: {e}\")\n",
    "        # Fallback to a list of common US tickers not in training set\n",
    "        fallback_tickers = [\n",
    "            'KO', 'PEP', 'JNJ', 'PG', 'WMT', 'HD', 'MCD', 'NKE', \n",
    "            'DIS', 'SBUX', 'COST', 'TGT', 'LOW', 'MO', 'CVS'\n",
    "        ]\n",
    "        fallback_tickers = [t for t in fallback_tickers if t not in training_tickers]\n",
    "        return np.random.choice(fallback_tickers, size=min(n_tickers, len(fallback_tickers)), replace=False).tolist()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Evaluate model (replace learn with your actual learner)\n",
    "    mae, rmse, r2 = evaluate_model(\n",
    "        learn=learn,  # Your fastai learner\n",
    "        test_tickers = get_random_test_tickers(n_tickers=testSize),\n",
    "        model_name=modelName,\n",
    "        model_folder=modelFolder,\n",
    "        cont_names=contNames,\n",
    "        cat_names=catNames\n",
    "    )\n",
    "    \n",
    "    if mae is not None and rmse is not None and r2 is not None:\n",
    "        print(f\"Evaluation Results:\")\n",
    "        print(f\"MAE: {mae:.3f}\")\n",
    "        print(f\"RMSE: {rmse:.3f}\")\n",
    "        print(f\"R2: {r2:.3f}\")\n",
    "    else:\n",
    "        print(\"Evaluation failed. Metrics are None.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(modelFolder / f'{modelName}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests (recommended to use the app instead, but feel free to use the tests below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To get prediction on a new dataframe, you can use the test_dl method of the DataLoaders. That dataframe does not need to have the dependent variable in its column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>EV/EBIT</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>ROIC</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232.119995</td>\n",
       "      <td>232.289993</td>\n",
       "      <td>228.479996</td>\n",
       "      <td>229.979996</td>\n",
       "      <td>68247100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.880474</td>\n",
       "      <td>3.458416e+12</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>Consumer Electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open        High         Low       Close    Volume  Dividends  \\\n",
       "0  232.119995  232.289993  228.479996  229.979996  68247100        0.0   \n",
       "\n",
       "   Stock Splits    EV/EBIT    Market Cap      ROIC              Industry  \n",
       "0           0.0  59.880474  3.458416e+12  0.013193  Consumer Electronics  "
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionTarget = 'AAPL'\n",
    "\n",
    "test_df = stockFetcher.getTickerData(predictionTarget)\n",
    "\n",
    "# Ensure test_df is a DataFrame\n",
    "if isinstance(test_df, dict):\n",
    "\ttest_df = pd.DataFrame([test_df])\n",
    "\n",
    "dl = learn.dls.test_dl(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for AAPL:\n",
      "-31.78%\n"
     ]
    }
   ],
   "source": [
    "prediction = learn.get_preds(dl=dl)\n",
    "print(f\"Prediction for {predictionTarget}:\")\n",
    "print(f\"{prediction[0][0][0].item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "Since machine learning models can’t magically understand categories it was never trained on, the data should reflect this. If there are different missing values in your test data you should address this before training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
