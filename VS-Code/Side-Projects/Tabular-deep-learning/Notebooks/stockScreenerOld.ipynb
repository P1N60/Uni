{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Screener: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Installation (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries the first time\n",
    "# ! conda install fastai::fastai conda-forge::yfinance pandas pathlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "from fastai.metrics import rmse, mae\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model settings\n",
    "modelName = 'stockScreenerV2.3'\n",
    "trainingData = 'stockData.csv'\n",
    "getNewData = False \n",
    "trainNewModel = False\n",
    "predictionTarget = 'PATH'  # 'ALL' for all, 'x%', 'None' for no prediction\n",
    "\n",
    "# Training parameters\n",
    "trainingSize = 1500  # Number of stocks to use for training\n",
    "timeFrame = '10y'   # Options: '1d', '5d', '1mo', '3mo', '6mo', '1y', '2y', '5y', '10y', 'ytd', 'max'\n",
    "yNames = ['Future Year Change']\n",
    "contNames = ['Open', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'EV/EBIT', 'ROIC']\n",
    "catNames = ['Industry', 'Date']\n",
    "batchSize = 512\n",
    "epochs = round(0.5 + np.log(trainingSize) ** 1.53)\n",
    "\n",
    "# Testing parameters\n",
    "testSize = 400  # Number of stocks to test, 'ALL' for all non-training stocks\n",
    "\n",
    "# Paths\n",
    "basePath = Path.cwd().parent\n",
    "dataFolder = basePath / 'TrainingData'\n",
    "modelFolder = basePath.parent / 'TrainedModels' / 'stockScreener'\n",
    "testFolder = basePath / 'TestData'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFutureYearChange(ticker_symbol, timeframe, buffer=1):\n",
    "    try:\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "        end_date = datetime.now().date()\n",
    "        \n",
    "        # Calculate required date range\n",
    "        if timeframe == 'max':\n",
    "            hist = ticker.history(period='max')\n",
    "        else:\n",
    "            years = int(timeframe[:-1])\n",
    "            start_date = end_date - pd.DateOffset(years=years + buffer)\n",
    "            \n",
    "            # First check if ticker has existed long enough\n",
    "            try:\n",
    "                hist = ticker.history(start=start_date, end=end_date)\n",
    "            except Exception as e:\n",
    "                print(f\"Data unavailable for {ticker_symbol} ({timeframe}): {e}\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "        if hist.empty:\n",
    "            print(f\"No data found for {ticker_symbol} ({timeframe})\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Calculate future changes only if we have enough data points\n",
    "        if len(hist) < 300:  # Minimum ~1.5 years of trading days\n",
    "            print(f\"Insufficient data for {ticker_symbol} ({len(hist)} rows)\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Calculate future price change\n",
    "        hist['Future Year Change'] = (hist['Close'].shift(-252) / hist['Close'] - 1)\n",
    "        hist = hist.dropna(subset=['Future Year Change'])\n",
    "        \n",
    "        return hist[['Open', 'Close', 'Volume', 'Dividends', 'Stock Splits', \n",
    "            'Future Year Change']].reset_index()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker_symbol}: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateApproxEBIT(tickerSymbol):\n",
    "    try:\n",
    "        info = yf.Ticker(tickerSymbol).info\n",
    "        revenue = info.get('totalRevenue', None)\n",
    "        operatingIncome = info.get('operatingIncome', None)\n",
    "        ebit = operatingIncome if operatingIncome else (revenue * 0.15 if revenue else None)\n",
    "        return ebit if ebit and ebit != 0 else None  # Avoid zero division\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichDataWithMetrics(histData):\n",
    "    # Initialize columns with NaN if they don't exist\n",
    "    if 'EV/EBIT' not in histData.columns:\n",
    "        histData['P/E'] = np.nan\n",
    "    if 'EV/EBIT' not in histData.columns:\n",
    "        histData['EV/EBIT'] = np.nan\n",
    "    if 'ROIC' not in histData.columns:\n",
    "        histData['ROIC'] = np.nan\n",
    "    \n",
    "    for ticker in histData['Ticker'].unique():\n",
    "        try:\n",
    "            evInfo = yf.Ticker(ticker).info\n",
    "            totalDebt, cash, sharesOutstanding = evInfo.get('totalDebt', 0), evInfo.get('totalCash', 0), evInfo.get('sharesOutstanding', None)\n",
    "            ebit = calculateApproxEBIT(ticker)\n",
    "\n",
    "            if sharesOutstanding and ebit and ebit != 0:\n",
    "                histData.loc[histData['Ticker'] == ticker, 'EV/EBIT'] = (\n",
    "                    (histData['Close'] * sharesOutstanding + totalDebt - cash) / ebit\n",
    "                )\n",
    "\n",
    "                taxRate = 0.21\n",
    "                nopat = ebit * (1 - taxRate)\n",
    "                investedCapital = totalDebt + (histData['Close'] * sharesOutstanding) - cash\n",
    "                histData.loc[histData['Ticker'] == ticker, 'ROIC'] = nopat / investedCapital\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return histData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTickerDataFrom1YrAgo(ticker_symbol):\n",
    "    try:\n",
    "        # Fetch ticker data\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "\n",
    "        # Define the date range: one year ago to today\n",
    "        today = datetime.today()\n",
    "        one_year_ago = today - timedelta(days=365)\n",
    "\n",
    "        # Fetch historical data for one year ago\n",
    "        hist = ticker.history(start=(one_year_ago - timedelta(days=30)).strftime('%Y-%m-%d'), \n",
    "                              end=(one_year_ago + timedelta(days=0)).strftime('%Y-%m-%d'))\n",
    "        if hist.empty:\n",
    "            raise ValueError(f\"No historical data available for {ticker_symbol} around {one_year_ago.strftime('%Y-%m-%d')}.\")\n",
    "\n",
    "        # Extract the closest data point to one year ago\n",
    "        row = hist.iloc[0]  # Get the first available entry within the date range\n",
    "\n",
    "        # Price today\n",
    "        price_today = ticker.history(period='1d')['Close'].iloc[-1]\n",
    "\n",
    "        # Calculate future price change (from one year ago to today)\n",
    "        price_change_future = ((price_today - row['Close']) / row['Close']) if row['Close'] else None\n",
    "\n",
    "        # Collect additional data\n",
    "        evInfo = yf.Ticker(ticker_symbol).info\n",
    "        total_debt, cash, shares_outstanding = evInfo.get('totalDebt', 0), evInfo.get('totalCash', 0), evInfo.get('sharesOutstanding', None)\n",
    "        ebit = calculateApproxEBIT(ticker_symbol)\n",
    "        ev = (row['Close'] * shares_outstanding) + total_debt - cash if shares_outstanding else None\n",
    "        ev_ebit = ev / ebit if ebit else None\n",
    "        market_cap = row['Close'] * shares_outstanding if shares_outstanding else None\n",
    "        tax_rate = 0.21\n",
    "        nopat = ebit * (1 - tax_rate) if ebit else None\n",
    "        invested_capital = total_debt + market_cap - cash if market_cap and total_debt and cash else None\n",
    "        roic = nopat / invested_capital if nopat and invested_capital else None\n",
    "        industry = yf.Ticker(ticker_symbol).info.get('industry', 'Unknown')\n",
    "\n",
    "        # Return as a DataFrame\n",
    "        return pd.DataFrame([{\n",
    "            'Ticker': ticker_symbol,\n",
    "            'Date': row.name,\n",
    "            'Open': row['Open'],\n",
    "            'High': row['High'],\n",
    "            'Low': row['Low'],\n",
    "            'Close': row['Close'],\n",
    "            'Volume': row['Volume'],\n",
    "            'Dividends': row.get('Dividends', 0.0),\n",
    "            'Stock Splits': row.get('Stock Splits', 0.0),\n",
    "            'Future Year Change': price_change_future,\n",
    "            'Industry': industry,\n",
    "            'EV/EBIT': ev_ebit,\n",
    "            'ROIC': roic\n",
    "        }])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker_symbol}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTickerData(ticker_symbol):\n",
    "    try:\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "        hist = ticker.history(period='1d')\n",
    "        evInfo = ticker.info\n",
    "        total_debt, cash, shares_outstanding = evInfo.get('totalDebt', 0), evInfo.get('totalCash', 0), evInfo.get('sharesOutstanding', None)\n",
    "        ebit = calculateApproxEBIT(ticker_symbol)\n",
    "        ev = (hist['Close'].iloc[-1] * shares_outstanding) + total_debt - cash\n",
    "        ev_ebit = ev / ebit if ebit else None\n",
    "        market_cap = hist['Close'].iloc[-1] * shares_outstanding\n",
    "        tax_rate = 0.21\n",
    "        nopat = ebit * (1 - tax_rate) if ebit else None\n",
    "        invested_capital = total_debt + market_cap - cash\n",
    "        roic = nopat / invested_capital if nopat and invested_capital else None\n",
    "        industry = yf.Ticker(ticker_symbol).info.get('industry', 'Unknown')\n",
    "        \n",
    "        # Add the 'Date' column\n",
    "        date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "        return pd.DataFrame([{\n",
    "            'Date': date,\n",
    "            'Open': hist['Open'].iloc[-1],\n",
    "            'High': hist['High'].iloc[-1],\n",
    "            'Low': hist['Low'].iloc[-1],\n",
    "            'Close': hist['Close'].iloc[-1],\n",
    "            'Volume': hist['Volume'].iloc[-1],\n",
    "            'Dividends': hist.get('Dividends', pd.Series([0.0])).iloc[-1],\n",
    "            'Stock Splits': hist.get('Stock Splits', pd.Series([0.0])).iloc[-1],\n",
    "            'EV/EBIT': ev_ebit,\n",
    "            'Market Cap': market_cap,\n",
    "            'ROIC': roic,\n",
    "            'Industry': industry\n",
    "        }])\n",
    "    except Exception:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Process Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = pd.read_csv(testFolder / 'filteredTickers.csv')['Ticker']\n",
    "trainingTickers = np.random.choice(tickers, size=trainingSize, replace=False)\n",
    "trainingRowAmount = len(pd.read_csv(testFolder / 'filteredTickers.csv'))\n",
    "\n",
    "if getNewData:\n",
    "    histData = pd.DataFrame()\n",
    "    valid_tickers = []\n",
    "    \n",
    "    for ticker in trainingTickers:\n",
    "        print(f\"Processing {ticker}...\")\n",
    "        try:\n",
    "            data = calculateFutureYearChange(ticker, timeFrame)\n",
    "            if not data.empty:\n",
    "                data['Ticker'] = ticker\n",
    "                data['Industry'] = yf.Ticker(ticker).info.get('industry', 'Unknown')\n",
    "                data['Date'] = pd.to_datetime(data['Date']).dt.tz_localize(None)\n",
    "                \n",
    "                # Enrich individual ticker data first\n",
    "                ticker_data = enrichDataWithMetrics(data)\n",
    "                histData = pd.concat([histData, ticker_data])\n",
    "                \n",
    "                # Check if metrics were added\n",
    "                if 'ROIC' not in ticker_data.columns:\n",
    "                    print(f\"WARNING: Failed to add metrics for {ticker}\")\n",
    "                \n",
    "                valid_tickers.append(ticker)\n",
    "            else:\n",
    "                print(f\"Skipped {ticker} - insufficient data\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker}: {e}\")\n",
    "\n",
    "    print(f\"\\nColumns in final dataset: {histData.columns.tolist()}\")\n",
    "    \n",
    "    if not histData.empty:\n",
    "        histData = enrichDataWithMetrics(histData)\n",
    "        histData.to_csv(dataFolder / trainingData, index=True)\n",
    "        # Verify no future targets leaked to past dates\n",
    "        latest_date = pd.to_datetime(histData['Date']).max()\n",
    "        if 'Future Year Change' in histData.columns:\n",
    "            target_dates = histData[histData['Future Year Change'].notnull()]['Date']\n",
    "            if any(pd.to_datetime(target_dates) > latest_date):\n",
    "                raise ValueError(\"CRITICAL: Analyst targets contain future dates!\")\n",
    "        trainingRowAmount = len(histData)\n",
    "        print(f\"Saved training data with {trainingRowAmount} rows\")\n",
    "    else:\n",
    "        print(\"Warning: No data collected - check your tickers list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if getNewData:\n",
    "    histData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainNewModel:\n",
    "    TRAINING_CUTOFF = pd.to_datetime('2023-01-01')\n",
    "\n",
    "    df = pd.read_csv(dataFolder / trainingData)\n",
    "    dfCleaned = df.dropna(subset=['EV/EBIT', 'ROIC']).copy()\n",
    "\n",
    "    # Convert 'Date' to datetime, parse UTC-aware dates, then make naive\n",
    "    dfCleaned['Date'] = pd.to_datetime(dfCleaned['Date'], errors='coerce', utc=True).dt.tz_convert(None)\n",
    "    dfCleaned = dfCleaned.dropna(subset=['Date'])\n",
    "\n",
    "    # Clean 'EV/EBIT' and reset index\n",
    "    dfCleaned['EV/EBIT'] = dfCleaned['EV/EBIT'].replace([np.inf, -np.inf], np.nan)\n",
    "    dfCleaned = dfCleaned.dropna(subset=['EV/EBIT', 'ROIC'])\n",
    "    dfCleaned = dfCleaned.reset_index(drop=True)\n",
    "    dfCleaned.to_csv(dataFolder / trainingData, index=False)\n",
    "\n",
    "    # Check for empty data\n",
    "    if dfCleaned.empty:\n",
    "        raise ValueError(\"The cleaned DataFrame is empty.\")\n",
    "\n",
    "    # Create splits with valid indices\n",
    "    train_mask = dfCleaned['Date'] < TRAINING_CUTOFF\n",
    "    valid_mask = ~train_mask\n",
    "    splits = (list(dfCleaned[train_mask].index), list(dfCleaned[valid_mask].index))\n",
    "\n",
    "    if not splits[0] or not splits[1]:\n",
    "        raise ValueError(\"Empty training or validation split.\")\n",
    "\n",
    "    # Proceed with TabularPandas\n",
    "    to = TabularPandas(\n",
    "        dfCleaned, \n",
    "        procs=[Categorify, FillMissing, Normalize],\n",
    "        y_names=yNames,\n",
    "        cat_names=catNames, \n",
    "        cont_names=contNames,\n",
    "        splits=splits\n",
    "    )\n",
    "\n",
    "    dls = to.dataloaders(bs=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainNewModel:\n",
    "    learn = tabular_learner(dls, metrics=[rmse, mae])\n",
    "\n",
    "    # Learning rate finder\n",
    "    lr_find_results = learn.lr_find(suggest_funcs=(minimum, steep))\n",
    "\n",
    "    # Debugging information\n",
    "    print(f\"Learning rate finder results: {lr_find_results}\")\n",
    "\n",
    "    # Extract learning rates\n",
    "    lr_min, lr_steep = lr_find_results\n",
    "\n",
    "    # Check if learning rates are valid\n",
    "    if lr_min is None or lr_steep is None or lr_min == 0 or lr_steep == 0:\n",
    "        raise ValueError(\"Learning rate finder did not return valid learning rates.\")\n",
    "\n",
    "    # Train\n",
    "    print(f\"Training for {epochs} epochs...\")\n",
    "    learn.fit_one_cycle(epochs, lr_max=lr_steep)\n",
    "    print(\"Model training complete\")\n",
    "\n",
    "    learn.export(modelFolder / f'{modelName}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logEvaluation(model_name, mae, rmse, r2, model_folder, test_tickers):\n",
    "    \"\"\"Log evaluation metrics to CSV file\"\"\"\n",
    "    log_file = model_folder / \"modelEvaluations.csv\"\n",
    "    \n",
    "    new_entry_df = pd.DataFrame([{\n",
    "        \"Model Name\": model_name,\n",
    "        \"Timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M'),\n",
    "        \"MAE\": f'{mae:.3f}',\n",
    "        \"RMSE\": f'{rmse:.3f}',\n",
    "        \"R2\": f'{r2:.3f}',\n",
    "        \"Epochs\": epochs,\n",
    "        \"Training Size\": trainingSize,\n",
    "        \"Training Rows\": trainingRowAmount,\n",
    "        \"Test Size\": len(test_tickers),\n",
    "        \"Cat Names\": catNames,\n",
    "        \"Cont Names\": contNames,\n",
    "    }])\n",
    "    \n",
    "    try:\n",
    "        log_df = pd.read_csv(log_file)\n",
    "        log_df = pd.concat([log_df, new_entry_df], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        log_df = new_entry_df\n",
    "        \n",
    "    log_df.to_csv(log_file, index=False)\n",
    "    print(f\"Logged evaluation results to {log_file}\")\n",
    "\n",
    "def plotResults(results_df, model_name, model_folder):\n",
    "    \"\"\"Create and save visualization plots using all data points.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.scatter(results_df['Actual'], results_df['Predicted'], alpha=0.7, label='Predictions')\n",
    "    min_val = min(results_df['Actual'].min(), results_df['Predicted'].min())\n",
    "    max_val = max(results_df['Actual'].max(), results_df['Predicted'].max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Perfect Prediction')\n",
    "    plt.title(f'Predicted vs. Actual Returns - {model_name}', fontsize=14)\n",
    "    plt.xlabel('Actual Returns')\n",
    "    plt.ylabel('Predicted Returns')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.5)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.scatter(results_df['Predicted'], results_df['Residual'], alpha=0.7)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.xlabel('Predicted Returns')\n",
    "    plt.ylabel('Residual')\n",
    "    plt.grid(alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if trainNewModel:\n",
    "    nonTrainingTickers = list(set(tickers) - set(trainingTickers))\n",
    "    validTestData = []\n",
    "    attempted_tickers = set()\n",
    "    attempts = 0\n",
    "\n",
    "    if testSize * 4 <= len(tickers):  \n",
    "        max_attempts = testSize * 4 # Prevent infinite loops\n",
    "    else:\n",
    "        max_attempts = len(tickers)\n",
    "\n",
    "    # Keep trying until we reach testSize or exhaust attempts\n",
    "    while len(validTestData) < testSize and attempts < max_attempts:\n",
    "        # Get a new ticker we haven't tried yet\n",
    "        remaining_tickers = [t for t in nonTrainingTickers if t not in attempted_tickers]\n",
    "        if not remaining_tickers:  # If all tried, reset attempted list\n",
    "            attempted_tickers = set()\n",
    "            remaining_tickers = nonTrainingTickers\n",
    "            \n",
    "        ticker = np.random.choice(remaining_tickers)\n",
    "        attempted_tickers.add(ticker)\n",
    "        attempts += 1\n",
    "\n",
    "        # Fetch and validate data\n",
    "        data = getTickerDataFrom1YrAgo(ticker)\n",
    "        if not data.empty and not data[['EV/EBIT', 'ROIC']].isna().any().any():\n",
    "            validTestData.append(data)\n",
    "\n",
    "    if not validTestData:\n",
    "        raise ValueError(\"No valid test data collected after multiple attempts\")\n",
    "        \n",
    "    # Trim to exact testSize if we collected more\n",
    "    validTestData = validTestData[:testSize]  \n",
    "    combinedTestData = pd.concat(validTestData, ignore_index=True)\n",
    "\n",
    "    # Clean data\n",
    "    test_data_clean = combinedTestData.dropna(subset=['EV/EBIT', 'ROIC', 'Future Year Change'])\n",
    "    \n",
    "    if test_data_clean.empty:\n",
    "        raise ValueError(\"No valid test data after cleaning NaN values\")\n",
    "\n",
    "    # Create test dataloader\n",
    "    test_dl = learn.dls.test_dl(test_data_clean)\n",
    "    preds, targs = learn.get_preds(dl=test_dl)\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Predicted': preds.numpy().flatten(),\n",
    "        'Actual': targs.numpy().flatten()\n",
    "    })\n",
    "    results_df['Residual'] = results_df['Actual'] - results_df['Predicted']\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(results_df['Residual']))\n",
    "    rmse = np.sqrt(np.mean(results_df['Residual']**2))\n",
    "    r2 = 1 - (np.sum(results_df['Residual']**2) / np.sum((results_df['Actual'] - results_df['Actual'].mean())**2))\n",
    "\n",
    "    # Log and plot\n",
    "    logEvaluation(modelName, mae, rmse, r2, modelFolder, test_data_clean['Ticker'].unique())\n",
    "    plotResults(results_df, modelName, modelFolder)\n",
    "\n",
    "    # Show collection stats\n",
    "    print(f\"Collected {len(validTestData)} valid test tickers (target: {testSize})\")\n",
    "    if attempts >= max_attempts:\n",
    "        print(f\"Warning: Reached max attempts ({max_attempts}). Some invalid tickers may remain.\")  \n",
    "    print(f\"\\nEvaluation Results:\")\n",
    "    print(f\"MAE: {mae:.3f}\")\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model files in modelFolder:\n",
      "stockScreenerV2.2.pkl\n",
      "stockScreenerV2.1.pkl\n",
      "stockScreenerV2.0.pkl\n",
      "stockScreenerV1.5.pkl\n",
      "stockScreenerV1.4.pkl\n",
      "stockScreenerV1.6.pkl\n",
      "stockScreenerV1.7.pkl\n",
      "stockScreenerV1.3.pkl\n",
      "stockScreenerV1.2.pkl\n",
      "stockScreenerV1.0.pkl\n",
      "stockScreenerV1.1.pkl\n",
      "stockScreenerV1.9.pkl\n",
      "stockScreenerV1.8.pkl\n",
      "stockScreenerV1.10.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Model files in modelFolder:')\n",
    "for file in modelFolder.glob('*.pkl'):\n",
    "    print(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Name    stockScreenerV1.7\n",
       "Timestamp      2025-01-27 08:45\n",
       "MAE                       0.328\n",
       "RMSE                      0.739\n",
       "R2                        0.077\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations = pd.read_csv(modelFolder / 'modelEvaluations.csv')\n",
    "bestModel = evaluations.sort_values('MAE', ascending=True).iloc[0]\n",
    "bestModel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "else:\n",
    "    pathlib.WindowsPath = pathlib.PosixPath\n",
    "\n",
    "importedModel = Path(f\"{bestModel['Model Name']}.pkl\") # Change this if you want to try other models\n",
    "learn = load_learner(modelFolder / importedModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictionTarget = '95%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for MAERSK-B.CO (Unknown):\n",
      "20.01%\n",
      "Free money?!\n"
     ]
    }
   ],
   "source": [
    "if predictionTarget != 'None':\n",
    "    if predictionTarget == 'ALL':\n",
    "        predictionTickers = tickers\n",
    "    elif predictionTarget.endswith('%'):\n",
    "        percentage = float(predictionTarget.strip('%')) / 100\n",
    "        num_tickers = int(len(tickers) * percentage)\n",
    "        predictionTickers = np.random.choice(tickers, size=num_tickers, replace=False).tolist()\n",
    "    else:\n",
    "        predictionTickers = [predictionTarget]\n",
    "\n",
    "    # Fetch data for prediction tickers\n",
    "    dfPrediction = pd.concat([getTickerData(ticker) for ticker in predictionTickers], ignore_index=True)\n",
    "\n",
    "    # Ensure dfPrediction is a DataFrame\n",
    "    if isinstance(dfPrediction, dict):\n",
    "        dfPrediction = pd.DataFrame([dfPrediction])\n",
    "\n",
    "    # Drop rows with NaN values in 'EV/EBIT' or 'ROIC'\n",
    "    dfPrediction = dfPrediction.dropna(subset=['EV/EBIT', 'ROIC'])\n",
    "\n",
    "    # Create test dataloader\n",
    "    dl = learn.dls.test_dl(dfPrediction)\n",
    "    dfPrediction.head()\n",
    "\n",
    "    # Make predictions\n",
    "    prediction = learn.get_preds(dl=dl)\n",
    "    adr_df = pd.read_csv(testFolder / 'filteredTickers.csv')\n",
    "    company_dict = dict(zip(adr_df['Ticker'], adr_df['Company']))\n",
    "\n",
    "    if predictionTarget == 'ALL' or predictionTarget.endswith('%'):\n",
    "        sorted_predictions = sorted(zip(predictionTickers, prediction[0]), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"Got predictions for {len(sorted_predictions)} tickers, expected: {len(predictionTickers)}\")\n",
    "        print(f\"Prediction for best performing tickers:\")\n",
    "        for symbol, pred in sorted_predictions:\n",
    "            company_name = company_dict.get(symbol, 'Unknown')\n",
    "            print(f\"{symbol} ({company_name}): {pred[0].item() * 100:.2f}%\")\n",
    "    else:\n",
    "        company_name = company_dict.get(predictionTarget, 'Unknown')\n",
    "        print(f\"Prediction for {predictionTarget} ({company_name}):\")\n",
    "        print(f\"{prediction[0][0][0].item() * 100:.2f}%\")\n",
    "    print(\"Free money?!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
